{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd3d5720",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:30.668146Z",
     "iopub.status.busy": "2024-03-14T14:46:30.667861Z",
     "iopub.status.idle": "2024-03-14T14:46:45.619914Z",
     "shell.execute_reply": "2024-03-14T14:46:45.618938Z"
    },
    "papermill": {
     "duration": 14.964194,
     "end_time": "2024-03-14T14:46:45.622304",
     "exception": false,
     "start_time": "2024-03-14T14:46:30.658110",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "import pandas as pd\n",
    "import os\n",
    "\"\"\"\n",
    "# CAN RUN THIS FROM ANY NOTEBOOK\n",
    " \n",
    "from spectrogram_preprocessor import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "spectrogram_dataset = SpectrogramDataset(\"train\", transform=transforms.Compose([\n",
    "    MiddleCrop(), Impute(), LogTransform(), StackFrequencyBands()])\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(spectrogram_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[\"values\"].shape) #, \"labels: \", sample_batched[1].shape)\n",
    "    print(sample_batched[\"seizure_vote\"].shape)\n",
    "    print(sample_batched[\"lpd_vote\"].shape)\n",
    "    print(sample_batched[\"gpd_vote\"].shape)\n",
    "    print(sample_batched[\"lrda_vote\"].shape)\n",
    "    print(sample_batched[\"grda_vote\"].shape)\n",
    "    print(len(sample_batched[\"target\"])) # for some reason target is a list\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    \"\"\"EEG spectrograms dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_type, csv_file=\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\", root_dir=\"/kaggle/input/hms-harmful-brain-activity-classification\", transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_type = data_type\n",
    "        if data_type == \"train\":\n",
    "            self.data_path = root_dir + \"/train_spectrograms\"\n",
    "            self.df_train = process_training_csv(csv_file)\n",
    "        elif data_type == \"test\":\n",
    "            self.data_path = root_dir + \"/test_spectrograms\"\n",
    "            print(f\"reading spectrograms from {self.data_path}\")\n",
    "            self.df_train = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def reset(self):\n",
    "        self.df_train = process_training_csv(\"hms-harmful-brain-activity-classification/train.csv\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if (self.data_type == \"train\"):\n",
    "            parquet_path = os.path.join(self.data_path, str(self.df_train.iloc[idx]['spec_id']) + \".parquet\")\n",
    "            parquet_table = pq.read_table(parquet_path)\n",
    "\n",
    "            sample = {\"values\" : parquet_table.to_pandas().values[:, 1:], # drop the time column\n",
    "                \"min\" : self.df_train.iloc[idx]['min'],\n",
    "                \"max\" : self.df_train.iloc[idx]['max']\n",
    "                }\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "                \n",
    "            if sample[\"values\"].shape[1]==0:\n",
    "                return self.__getitem__(np.random.choice(len(self.data)))\n",
    "\n",
    "            seizure_vote = self.df_train.iloc[idx]['seizure_vote']\n",
    "            lpd_vote = self.df_train.iloc[idx]['lpd_vote']\n",
    "            gpd_vote = self.df_train.iloc[idx]['gpd_vote']\n",
    "            lrda_vote = self.df_train.iloc[idx]['lrda_vote']\n",
    "            grda_vote = self.df_train.iloc[idx]['grda_vote']\n",
    "            other_vote = self.df_train.iloc[idx]['other_vote']\n",
    "            target = self.df_train.iloc[idx]['target']\n",
    "\n",
    "            sample = {\n",
    "                \"values\": sample[\"values\"],\n",
    "                \"seizure_vote\": seizure_vote,\n",
    "                \"lpd_vote\": lpd_vote,\n",
    "                \"gpd_vote\": gpd_vote,\n",
    "                \"lrda_vote\": lrda_vote,\n",
    "                \"grda_vote\": grda_vote,\n",
    "                \"other_vote\": other_vote,\n",
    "                \"target\": target\n",
    "            }\n",
    "        else:\n",
    "            #spectrogram_id eeg_id patient_id\n",
    "            parquet_path = os.path.join(self.data_path, str(self.df_train.iloc[idx]['spectrogram_id']) + \".parquet\")\n",
    "            parquet_table = pq.read_table(parquet_path)\n",
    "            \n",
    "            sample = {\"values\" : parquet_table.to_pandas().values[:, 1:], # drop the time column\n",
    "                \"min\" : 0,\n",
    "                \"max\" : 0\n",
    "                }\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "            \n",
    "            sample = {\n",
    "                \"values\": sample[\"values\"],\n",
    "                \"patient_id\": self.df_train.iloc[idx]['patient_id']\n",
    "            }\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def process_training_csv(csv_file):\n",
    "    \"\"\"\n",
    "    csv preprocessing from example notebook:\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    TARGETS = df.columns[-6:]\n",
    "    # Creating a Unique EEG Segment per eeg_id:\n",
    "    # The code groups (groupby) the EEG data (df) by eeg_id. Each eeg_id represents a different EEG recording.\n",
    "    # It then picks the first spectrogram_id and the earliest (min) spectrogram_label_offset_seconds for each eeg_id. This helps in identifying the starting point of each EEG segment.\n",
    "    # The resulting DataFrame train has columns spec_id (first spectrogram_id) and min (earliest spectrogram_label_offset_seconds).\n",
    "    train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "        {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
    "    train.columns = ['spec_id','min']\n",
    "    # Finding the Latest Point in Each EEG Segment:\n",
    "    # The code again groups the data by eeg_id and finds the latest (max) spectrogram_label_offset_seconds for each segment.\n",
    "    # This max value is added to the train DataFrame, representing the end point of each EEG segment.\n",
    "    tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "        {'spectrogram_label_offset_seconds':'max'})\n",
    "    train['max'] = tmp\n",
    "    # The code adds the patient_id for each eeg_id to the train DataFrame. This links each EEG segment to a specific patient.\n",
    "    tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
    "    train['patient_id'] = tmp\n",
    "    # The code sums up the target variable counts (like votes for seizure, LPD, etc.) for each eeg_id.\n",
    "    tmp = df.groupby('eeg_id')[TARGETS].agg('sum') \n",
    "    for t in TARGETS:\n",
    "        train[t] = tmp[t].values\n",
    "    # It then normalizes these counts so that they sum up to 1. This step converts the counts into probabilities, which is a common practice in classification tasks.\n",
    "    y_data = train[TARGETS].values \n",
    "    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "    train[TARGETS] = y_data\n",
    "    # For each eeg_id, the code includes the expert_consensus on the EEG segment's classification.\n",
    "    tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
    "    train['target'] = tmp\n",
    "    # This makes eeg_id a regular column, making the DataFrame easier to work with.\n",
    "    train = train.reset_index() \n",
    "    print('Train non-overlapp eeg_id shape:', train.shape)\n",
    "    return train\n",
    "\n",
    "\n",
    "class MiddleCrop(object):\n",
    "    \"\"\"Crop the spectrogram in a sample, centred in the middle.\n",
    "\n",
    "    Args:\n",
    "        output_size: Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size=300):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # //2 for average, //2 for 2 seconds per bin (min and max are in seconds, spectrogram is 2 seconds per value)\n",
    "        start_from = int((sample[\"min\"] + sample[\"max\"]) // 4) \n",
    "        cropped = sample[\"values\"][start_from:start_from+self.output_size, :]\n",
    "        return {\"values\": cropped, \"min\": 0, \"max\": self.output_size*2}\n",
    "    \n",
    "class Impute(object):\n",
    "    \"\"\"\n",
    "    replace NaNs with mean\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nan_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imputed = self.nan_imputer.fit_transform(sample[\"values\"])\n",
    "        return {\"values\": imputed, \"min\": sample[\"min\"], \"max\": sample[\"max\"]}\n",
    "    \n",
    "class StackFrequencyBands(object):\n",
    "    \"\"\"Stack the 4 frequency bands of the spectrogram in a sample.\n",
    "\n",
    "    \"Args:\n",
    "        sample: 300x400 spectrogram\n",
    "        returns: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        values = sample[\"values\"]\n",
    "        split_arrays = np.array(np.split(values, 4, axis=1))\n",
    "        return {\n",
    "            \"values\": split_arrays,\n",
    "                \"min\": sample[\"min\"],\n",
    "                \"max\": sample[\"max\"]\n",
    "        }\n",
    "\n",
    "class LogTransform(object):\n",
    "    \"\"\"Apply log transformation to the spectrogram in a sample.\n",
    "\n",
    "    Args:\n",
    "        sample: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "        returns: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        values = sample[\"values\"]\n",
    "        log_transformed = np.log(values + 1)\n",
    "        return {\n",
    "            \"values\": log_transformed,\n",
    "                \"min\": sample[\"min\"],\n",
    "                \"max\": sample[\"max\"]\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66e8c00d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:45.638887Z",
     "iopub.status.busy": "2024-03-14T14:46:45.638403Z",
     "iopub.status.idle": "2024-03-14T14:46:45.789814Z",
     "shell.execute_reply": "2024-03-14T14:46:45.789086Z"
    },
    "papermill": {
     "duration": 0.161947,
     "end_time": "2024-03-14T14:46:45.792015",
     "exception": false,
     "start_time": "2024-03-14T14:46:45.630068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import torch.nn.init as init\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"\n",
    "Ideas To Prevent Loss Nans\n",
    "1. Normalize Data Better\n",
    "2. Less Deep / Wide Architecture\n",
    "3. CNN instead of FCNN\n",
    "\"\"\"\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, numFrequencies, numRows, numFeatures=100):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder with Batch Normalization\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFrequencies * numRows, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFeatures),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Building a linear decoder with Batch Normalization\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFeatures, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFrequencies * numRows),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization to the weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826f6667",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:45.808368Z",
     "iopub.status.busy": "2024-03-14T14:46:45.808048Z",
     "iopub.status.idle": "2024-03-14T14:46:45.817908Z",
     "shell.execute_reply": "2024-03-14T14:46:45.817105Z"
    },
    "papermill": {
     "duration": 0.020259,
     "end_time": "2024-03-14T14:46:45.819966",
     "exception": false,
     "start_time": "2024-03-14T14:46:45.799707",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Ideas To Prevent Loss Nans\n",
    "1. Normalize Data Better\n",
    "2. Less Deep / Wide Architecture\n",
    "3. CNN instead of FCNN\n",
    "\"\"\"\n",
    "class AEW(torch.nn.Module):\n",
    "    def __init__(self, numFrequencies, numRows, numFeatures=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder with Batch Normalization\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFrequencies * numRows, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFeatures),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Building a linear decoder with Batch Normalization\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFeatures, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFrequencies * numRows),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization to the weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "738848c6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:45.836280Z",
     "iopub.status.busy": "2024-03-14T14:46:45.836019Z",
     "iopub.status.idle": "2024-03-14T14:46:45.841186Z",
     "shell.execute_reply": "2024-03-14T14:46:45.840349Z"
    },
    "papermill": {
     "duration": 0.015527,
     "end_time": "2024-03-14T14:46:45.843042",
     "exception": false,
     "start_time": "2024-03-14T14:46:45.827515",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "alpha_frequencies = 21 * 4\n",
    "delta_frequencies = 18 * 4\n",
    "theta_frequencies = 20 * 4\n",
    "beta_frequencies = 41 * 4\n",
    "SPEC_FREQS = 400\n",
    "\n",
    "numFeatures = 400\n",
    "\n",
    "ALPHA_PATH = \"/kaggle/input/alpha-band-autoencoder-model/model_alpha_latest.pth\"\n",
    "BETA_PATH = \"/kaggle/input/beta-band-autoencoder-model/model_beta_latest.pth\"\n",
    "DELTA_PATH = \"/kaggle/input/delta-band-autoencoder-model/model_delta_latest.pth\"\n",
    "THETA_PATH = \"/kaggle/input/theta-band-autoencoder-model/model_theta_latest.pth\"\n",
    "TEN_MIN_PATH = \"/kaggle/input/window10min-autoencoder-version2/model_ten_min_latest.pth\"\n",
    "TWENTY_SEC_PATH = \"/kaggle/input/window20sec-autoencoder-version2/model_20sec_latest.pth\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbaa5c00",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:45.859393Z",
     "iopub.status.busy": "2024-03-14T14:46:45.858847Z",
     "iopub.status.idle": "2024-03-14T14:46:45.959125Z",
     "shell.execute_reply": "2024-03-14T14:46:45.958485Z"
    },
    "papermill": {
     "duration": 0.110695,
     "end_time": "2024-03-14T14:46:45.960996",
     "exception": false,
     "start_time": "2024-03-14T14:46:45.850301",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "PATH = \"/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/\"\n",
    "def extract_frequency_band_features(segment):\n",
    "    \n",
    "    cols = pd.read_parquet(f'{PATH}1000086677.parquet').columns[1:] # like LR_14.32\n",
    "    channel_groups = ['LL', 'RL', 'LP', 'RP']\n",
    "    \n",
    "    eeg_bands = {'Delta': (0.5, 4), 'Theta': (4, 8), 'Alpha': (8, 12), 'Beta': (12, 30)}\n",
    "    band_datapoints = {\n",
    "        \"Alpha\": [],\n",
    "        \"Delta\": [],\n",
    "        \"Theta\": [],\n",
    "        \"Beta\": [],\n",
    "    }\n",
    "    \n",
    "    for channel_group in channel_groups:\n",
    "        for band in eeg_bands:\n",
    "            low, high = eeg_bands[band]\n",
    "            # Filter signal for the specific band\n",
    "            idxs = []\n",
    "            for idx, col in enumerate(cols):\n",
    "                if channel_group in col and float(col.split(\"_\")[1]) <= high and float(col.split(\"_\")[1]) >= low:\n",
    "                    idxs.append(idx)\n",
    "                        \n",
    "            filtered = segment[:, idxs].flatten()\n",
    "            band_datapoints[band].append(filtered)\n",
    "    \n",
    "    for band in band_datapoints:\n",
    "        band_datapoints[band] = np.array(band_datapoints[band]).flatten() \n",
    "        # join all 4 group signals into one to reconstruct in autoencoder\n",
    "    return band_datapoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "85a435a2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:46:45.976818Z",
     "iopub.status.busy": "2024-03-14T14:46:45.976419Z",
     "iopub.status.idle": "2024-03-14T14:47:16.285831Z",
     "shell.execute_reply": "2024-03-14T14:47:16.284858Z"
    },
    "papermill": {
     "duration": 30.327363,
     "end_time": "2024-03-14T14:47:16.295738",
     "exception": false,
     "start_time": "2024-03-14T14:46:45.968375",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AE(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=24000, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=2048, out_features=400, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=400, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=2048, out_features=24000, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    print('Use Multi GPU', device)\n",
    "else:\n",
    "    device = torch.device('cpu') \n",
    "    print(\"Use CPU\")\n",
    "    \n",
    "\n",
    "# load model alpha from memory:\n",
    "model_alpha = AE(alpha_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_alpha.to(device)\n",
    "    model_alpha = nn.DataParallel(module=model_alpha)\n",
    "    print('Use Multi GPU', device)\n",
    "model_alpha.load_state_dict(torch.load(ALPHA_PATH))\n",
    "model_alpha.eval()\n",
    "\n",
    "# load model beta from memory:\n",
    "model_beta = AE(beta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_beta.to(device)\n",
    "    model_beta = nn.DataParallel(module=model_beta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_beta.load_state_dict(torch.load(BETA_PATH))\n",
    "model_beta.eval()\n",
    "\n",
    "# load model delta from memory:\n",
    "model_delta = AE(delta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_delta.to(device)\n",
    "    model_delta = nn.DataParallel(module=model_delta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_delta.load_state_dict(torch.load(DELTA_PATH))\n",
    "model_delta.eval()\n",
    "\n",
    "# load model theta from memory:\n",
    "model_theta = AE(theta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_theta.to(device)\n",
    "    model_theta = nn.DataParallel(module=model_theta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_theta.load_state_dict(torch.load(THETA_PATH))\n",
    "model_theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76affe85",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:47:16.312810Z",
     "iopub.status.busy": "2024-03-14T14:47:16.312519Z",
     "iopub.status.idle": "2024-03-14T14:47:44.083441Z",
     "shell.execute_reply": "2024-03-14T14:47:44.082521Z"
    },
    "papermill": {
     "duration": 27.781921,
     "end_time": "2024-03-14T14:47:44.085617",
     "exception": false,
     "start_time": "2024-03-14T14:47:16.303696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device:  cpu\n",
      "Use device:  cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AEW(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4000, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=4000, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_window = torch.device('cpu')\n",
    "\n",
    "# load model 10min from memory:\n",
    "model_10min = AEW(SPEC_FREQS, 300, numFeatures=numFeatures)\n",
    "model_10min = model_10min.to(device_window)\n",
    "print('Use device: ', device_window)\n",
    "model_10min.load_state_dict(torch.load(TEN_MIN_PATH))\n",
    "model_10min.eval()\n",
    "\n",
    "# load model 20sec from memory:\n",
    "model_20sec = AEW(SPEC_FREQS, 10, numFeatures=numFeatures)\n",
    "model_20sec = model_20sec.to(device_window)\n",
    "print('Use device: ', device_window)\n",
    "model_20sec.load_state_dict(torch.load(TWENTY_SEC_PATH))\n",
    "model_20sec.eval()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "213b9551",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T14:47:44.105165Z",
     "iopub.status.busy": "2024-03-14T14:47:44.104809Z",
     "iopub.status.idle": "2024-03-14T15:14:58.036249Z",
     "shell.execute_reply": "2024-03-14T15:14:58.035183Z"
    },
    "papermill": {
     "duration": 1633.964325,
     "end_time": "2024-03-14T15:14:58.058742",
     "exception": false,
     "start_time": "2024-03-14T14:47:44.094417",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train non-overlapp eeg_id shape: (17089, 12)\n",
      "Generating 2400 features on 17089 datapoints\n",
      "batch  0... batch  1... batch  2... batch  3... batch  4... batch  5... batch  6... batch  7... batch  8... batch  9... batch  10... batch  11... batch  12... batch  13... batch  14... batch  15... batch  16... batch  17... batch  18... batch  19... batch  20... batch  21... batch  22... batch  23... batch  24... batch  25... batch  26... batch  27... batch  28... batch  29... batch  30... batch  31... batch  32... batch  33... batch  34... batch  35... batch  36... batch  37... batch  38... batch  39... batch  40... batch  41... batch  42... batch  43... batch  44... batch  45... batch  46... batch  47... batch  48... batch  49... batch  50... batch  51... batch  52... batch  53... batch  54... batch  55... batch  56... batch  57... batch  58... batch  59... batch  60... batch  61... batch  62... batch  63... batch  64... batch  65... batch  66... batch  67... batch  68... batch  69... batch  70... batch  71... batch  72... batch  73... batch  74... batch  75... batch  76... batch  77... batch  78... batch  79... batch  80... batch  81... batch  82... batch  83... batch  84... batch  85... batch  86... batch  87... batch  88... batch  89... batch  90... batch  91... batch  92... batch  93... batch  94... batch  95... batch  96... batch  97... batch  98... batch  99... batch  100... batch  101... batch  102... batch  103... batch  104... batch  105... batch  106... batch  107... batch  108... batch  109... batch  110... batch  111... batch  112... batch  113... batch  114... batch  115... batch  116... batch  117... batch  118... batch  119... batch  120... batch  121... batch  122... batch  123... batch  124... batch  125... batch  126... batch  127... batch  128... batch  129... batch  130... batch  131... batch  132... batch  133... batch  134... batch  135... batch  136... batch  137... batch  138... batch  139... batch  140... batch  141... batch  142... batch  143... batch  144... batch  145... batch  146... batch  147... batch  148... batch  149... batch  150... batch  151... batch  152... batch  153... batch  154... batch  155... batch  156... batch  157... batch  158... batch  159... batch  160... batch  161... batch  162... batch  163... batch  164... batch  165... batch  166... batch  167... batch  168... batch  169... batch  170... New train shape:  (17089, 2400)\n",
      "Labels shape:  (17089, 6)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get Feature Data\n",
    "\"\"\"\n",
    "batch_size = 100\n",
    "\n",
    "FEATURES = [\"feature_{}_alpha\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_beta\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_delta\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_theta\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_10min\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_20sec\".format(i) for i in range(numFeatures)]\n",
    "\n",
    "\n",
    "spectrogram_dataset = SpectrogramDataset(\"train\", transform=transforms.Compose([\n",
    "    MiddleCrop(), Impute(), LogTransform()])\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(spectrogram_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)\n",
    "\n",
    "print(f\"Generating {len(FEATURES)} features on {len(spectrogram_dataset)} datapoints\")\n",
    "# train data\n",
    "data = np.zeros((len(spectrogram_dataset), len(FEATURES)))\n",
    "# train labels\n",
    "labels = np.zeros((len(spectrogram_dataset), 6))\n",
    "\n",
    "for k, batch in enumerate(dataloader):\n",
    "    print(\"batch \", k, end=\"... \")\n",
    "    b_size = batch[\"values\"].shape[0] # this batch's size may be different from batch_size (mainly for last batch)\n",
    "\n",
    "    labels[k*batch_size:k*batch_size + b_size, 0] = batch[\"seizure_vote\"]\n",
    "    labels[k*batch_size:k*batch_size + b_size, 1] = batch[\"lpd_vote\"]\n",
    "    labels[k*batch_size:k*batch_size + b_size, 2] = batch[\"gpd_vote\"]\n",
    "    labels[k*batch_size:k*batch_size + b_size, 3] = batch[\"lrda_vote\"]\n",
    "    labels[k*batch_size:k*batch_size + b_size, 4] = batch[\"grda_vote\"]\n",
    "    labels[k*batch_size:k*batch_size + b_size, 5] = batch[\"other_vote\"]\n",
    "    \n",
    "    \n",
    "    for i, eeg_segment in enumerate(batch[\"values\"]):\n",
    "        \n",
    "        signals = {\n",
    "            \"Alpha\": [], \"Beta\": [], \"Delta\": [], \"Theta\": []\n",
    "        }\n",
    "    \n",
    "        signals = extract_frequency_band_features(eeg_segment)\n",
    "            \n",
    "        vals = signals[\"Alpha\"]\n",
    "        if len(vals) == alpha_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_alpha.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 0:numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Beta\"]\n",
    "        if len(vals) == beta_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_beta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, numFeatures:2*numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Delta\"]\n",
    "        if len(vals) == delta_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_delta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 2*numFeatures:3*numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Theta\"]\n",
    "        if len(vals) == theta_frequencies * 300 * 4:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_theta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 3*numFeatures:4*numFeatures] = x\n",
    "        \n",
    "        # 10 MINUTE WINDOW FEATURES\n",
    "        raw_values_10min = eeg_segment.flatten()\n",
    "        normalized_values_10min = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "        x = np.array(model_10min.encoder(torch.tensor(np.array(normalized_values_10min).reshape(1,-1), dtype=torch.float32).to(device_window)).tolist())    \n",
    "        data[k*batch_size + i,4*numFeatures:5*numFeatures] = x\n",
    "\n",
    "        # 20 SECOND WINDOW FEATURES\n",
    "        raw_values_20sec = eeg_segment[145:155].flatten()\n",
    "        normalized_values_20sec = (raw_values_20sec - raw_values_20sec.min()) / (raw_values_20sec.max() - raw_values_20sec.min())\n",
    "        x = np.array(model_20sec.encoder(torch.tensor(np.array(normalized_values_20sec).reshape(1,-1), dtype=torch.float32).to(device_window)).tolist())\n",
    "        data[k*batch_size + i,5*numFeatures:6*numFeatures] = x\n",
    "\n",
    "#train[FEATURES] = data\n",
    "\n",
    "print('New train shape: ', data.shape)\n",
    "print('Labels shape: ', labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6cd77bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:14:58.102527Z",
     "iopub.status.busy": "2024-03-14T15:14:58.102184Z",
     "iopub.status.idle": "2024-03-14T15:14:58.227240Z",
     "shell.execute_reply": "2024-03-14T15:14:58.226366Z"
    },
    "papermill": {
     "duration": 0.149122,
     "end_time": "2024-03-14T15:14:58.229192",
     "exception": false,
     "start_time": "2024-03-14T15:14:58.080070",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model_alpha, model_beta, model_delta, model_theta, model_10min, model_20sec\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9c5399e1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:14:58.273433Z",
     "iopub.status.busy": "2024-03-14T15:14:58.273069Z",
     "iopub.status.idle": "2024-03-14T15:15:49.250834Z",
     "shell.execute_reply": "2024-03-14T15:15:49.249994Z"
    },
    "papermill": {
     "duration": 51.002407,
     "end_time": "2024-03-14T15:15:49.253168",
     "exception": false,
     "start_time": "2024-03-14T15:14:58.250761",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform them\n",
    "features_scaled = scaler.fit_transform(data)\n",
    "\n",
    "# Create a DataFrame from the scaled features\n",
    "train_scaled_df = pd.DataFrame(features_scaled)\n",
    "train_labels_df = pd.DataFrame(labels)\n",
    "\n",
    "train_scaled_df.to_csv(\"/kaggle/working/train_scaled.csv\")\n",
    "train_labels_df.to_csv(\"/kaggle/working/train_labels.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6592bdec",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:15:49.298574Z",
     "iopub.status.busy": "2024-03-14T15:15:49.298164Z",
     "iopub.status.idle": "2024-03-14T15:15:54.415857Z",
     "shell.execute_reply": "2024-03-14T15:15:54.414927Z"
    },
    "papermill": {
     "duration": 5.142893,
     "end_time": "2024-03-14T15:15:54.418189",
     "exception": false,
     "start_time": "2024-03-14T15:15:49.275296",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>2390</th>\n",
       "      <th>2391</th>\n",
       "      <th>2392</th>\n",
       "      <th>2393</th>\n",
       "      <th>2394</th>\n",
       "      <th>2395</th>\n",
       "      <th>2396</th>\n",
       "      <th>2397</th>\n",
       "      <th>2398</th>\n",
       "      <th>2399</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>...</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.0</td>\n",
       "      <td>17089.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>-4.428159e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.315791e-19</td>\n",
       "      <td>-1.496842e-17</td>\n",
       "      <td>8.107896e-18</td>\n",
       "      <td>2.494737e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.455263e-18</td>\n",
       "      <td>4.906317e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.600790e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.906317e-17</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>-1.223781e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.180790e-02</td>\n",
       "      <td>-4.594322e-01</td>\n",
       "      <td>-7.649876e-03</td>\n",
       "      <td>-1.883016e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.445370e-02</td>\n",
       "      <td>-1.732432e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.084701e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-9.271445e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>-1.223781e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.180790e-02</td>\n",
       "      <td>-4.594322e-01</td>\n",
       "      <td>-7.649876e-03</td>\n",
       "      <td>-1.883016e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.445370e-02</td>\n",
       "      <td>-1.732432e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.159386e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-7.851902e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>-1.223781e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.180790e-02</td>\n",
       "      <td>-4.594322e-01</td>\n",
       "      <td>-7.649876e-03</td>\n",
       "      <td>-1.883016e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.445370e-02</td>\n",
       "      <td>-1.732432e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.873895e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-2.279119e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>-1.223781e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.180790e-02</td>\n",
       "      <td>-2.599162e-03</td>\n",
       "      <td>-7.649876e-03</td>\n",
       "      <td>-1.883016e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.445370e-02</td>\n",
       "      <td>-1.732432e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.255914e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.364051e-01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2.906922e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.141936e+02</td>\n",
       "      <td>1.300626e+01</td>\n",
       "      <td>1.307211e+02</td>\n",
       "      <td>9.081096e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.645970e+01</td>\n",
       "      <td>2.642697e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.007905e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.090353e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 2400 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               0        1             2             3             4     \\\n",
       "count  1.708900e+04  17089.0  1.708900e+04  1.708900e+04  1.708900e+04   \n",
       "mean  -4.428159e-17      0.0  8.315791e-19 -1.496842e-17  8.107896e-18   \n",
       "std    1.000029e+00      0.0  1.000029e+00  1.000029e+00  1.000029e+00   \n",
       "min   -1.223781e-01      0.0 -1.180790e-02 -4.594322e-01 -7.649876e-03   \n",
       "25%   -1.223781e-01      0.0 -1.180790e-02 -4.594322e-01 -7.649876e-03   \n",
       "50%   -1.223781e-01      0.0 -1.180790e-02 -4.594322e-01 -7.649876e-03   \n",
       "75%   -1.223781e-01      0.0 -1.180790e-02 -2.599162e-03 -7.649876e-03   \n",
       "max    2.906922e+01      0.0  1.141936e+02  1.300626e+01  1.307211e+02   \n",
       "\n",
       "               5        6             7             8        9     ...  \\\n",
       "count  1.708900e+04  17089.0  1.708900e+04  1.708900e+04  17089.0  ...   \n",
       "mean   2.494737e-18      0.0 -1.455263e-18  4.906317e-17      0.0  ...   \n",
       "std    1.000029e+00      0.0  1.000029e+00  1.000029e+00      0.0  ...   \n",
       "min   -1.883016e-02      0.0 -1.445370e-02 -1.732432e-01      0.0  ...   \n",
       "25%   -1.883016e-02      0.0 -1.445370e-02 -1.732432e-01      0.0  ...   \n",
       "50%   -1.883016e-02      0.0 -1.445370e-02 -1.732432e-01      0.0  ...   \n",
       "75%   -1.883016e-02      0.0 -1.445370e-02 -1.732432e-01      0.0  ...   \n",
       "max    9.081096e+01      0.0  8.645970e+01  2.642697e+01      0.0  ...   \n",
       "\n",
       "          2390     2391          2392     2393     2394     2395     2396  \\\n",
       "count  17089.0  17089.0  1.708900e+04  17089.0  17089.0  17089.0  17089.0   \n",
       "mean       0.0      0.0  1.600790e-17      0.0      0.0      0.0      0.0   \n",
       "std        0.0      0.0  1.000029e+00      0.0      0.0      0.0      0.0   \n",
       "min        0.0      0.0 -1.084701e+00      0.0      0.0      0.0      0.0   \n",
       "25%        0.0      0.0 -7.159386e-01      0.0      0.0      0.0      0.0   \n",
       "50%        0.0      0.0 -1.873895e-01      0.0      0.0      0.0      0.0   \n",
       "75%        0.0      0.0  4.255914e-01      0.0      0.0      0.0      0.0   \n",
       "max        0.0      0.0  1.007905e+01      0.0      0.0      0.0      0.0   \n",
       "\n",
       "               2397     2398     2399  \n",
       "count  1.708900e+04  17089.0  17089.0  \n",
       "mean   4.906317e-17      0.0      0.0  \n",
       "std    1.000029e+00      0.0      0.0  \n",
       "min   -9.271445e-01      0.0      0.0  \n",
       "25%   -7.851902e-01      0.0      0.0  \n",
       "50%   -2.279119e-01      0.0      0.0  \n",
       "75%    4.364051e-01      0.0      0.0  \n",
       "max    1.090353e+01      0.0      0.0  \n",
       "\n",
       "[8 rows x 2400 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "75128b77",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:15:54.464776Z",
     "iopub.status.busy": "2024-03-14T15:15:54.464494Z",
     "iopub.status.idle": "2024-03-14T15:15:54.490143Z",
     "shell.execute_reply": "2024-03-14T15:15:54.489171Z"
    },
    "papermill": {
     "duration": 0.050501,
     "end_time": "2024-03-14T15:15:54.491995",
     "exception": false,
     "start_time": "2024-03-14T15:15:54.441494",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.152810</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.114851</td>\n",
       "      <td>0.420413</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.331563</td>\n",
       "      <td>0.295541</td>\n",
       "      <td>0.258825</td>\n",
       "      <td>0.187005</td>\n",
       "      <td>0.271425</td>\n",
       "      <td>0.418454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.941176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  0             1             2             3             4  \\\n",
       "count  17089.000000  17089.000000  17089.000000  17089.000000  17089.000000   \n",
       "mean       0.152810      0.142456      0.104062      0.065407      0.114851   \n",
       "std        0.331563      0.295541      0.258825      0.187005      0.271425   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.068966      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "                  5  \n",
       "count  17089.000000  \n",
       "mean       0.420413  \n",
       "std        0.418454  \n",
       "min        0.000000  \n",
       "25%        0.000000  \n",
       "50%        0.333333  \n",
       "75%        0.941176  \n",
       "max        1.000000  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8123de0b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:15:54.537159Z",
     "iopub.status.busy": "2024-03-14T15:15:54.536882Z",
     "iopub.status.idle": "2024-03-14T15:15:54.887370Z",
     "shell.execute_reply": "2024-03-14T15:15:54.886350Z"
    },
    "papermill": {
     "duration": 0.375496,
     "end_time": "2024-03-14T15:15:54.889578",
     "exception": false,
     "start_time": "2024-03-14T15:15:54.514082",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import gc\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b125a699",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:15:54.935255Z",
     "iopub.status.busy": "2024-03-14T15:15:54.934969Z",
     "iopub.status.idle": "2024-03-14T15:15:54.939655Z",
     "shell.execute_reply": "2024-03-14T15:15:54.938797Z"
    },
    "papermill": {
     "duration": 0.029382,
     "end_time": "2024-03-14T15:15:54.941532",
     "exception": false,
     "start_time": "2024-03-14T15:15:54.912150",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features:  2400\n",
      "(17089, 2400)\n",
      "(17089, 6)\n"
     ]
    }
   ],
   "source": [
    "print(\"features: \", len(FEATURES))\n",
    "print(train_scaled_df.shape)\n",
    "print(train_labels_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a6b924cf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:15:54.986794Z",
     "iopub.status.busy": "2024-03-14T15:15:54.986555Z",
     "iopub.status.idle": "2024-03-14T15:35:20.489890Z",
     "shell.execute_reply": "2024-03-14T15:35:20.488958Z"
    },
    "papermill": {
     "duration": 1165.551442,
     "end_time": "2024-03-14T15:35:20.515038",
     "exception": false,
     "start_time": "2024-03-14T15:15:54.963596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "KL divergence:  0.7560883088372607\n",
      "#########################\n",
      "### Fold 2\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "KL divergence:  0.7723165561193774\n",
      "#########################\n",
      "### Fold 3\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "KL divergence:  0.7509126041568722\n",
      "#########################\n",
      "### Fold 4\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "KL divergence:  0.8173506473712132\n",
      "#########################\n",
      "### Fold 5\n",
      "### train size 13672, valid size 3417\n",
      "#########################\n",
      "KL divergence:  0.7707770461161145\n"
     ]
    }
   ],
   "source": [
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.stats import entropy\n",
    "import joblib\n",
    "\n",
    "all_oof = []\n",
    "all_true = []\n",
    "\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "kf = KFold(n_splits=5)\n",
    "for i, (train_index, valid_index) in enumerate(kf.split(train_scaled_df)):   \n",
    "    if i >= n_splits:\n",
    "        continue\n",
    "    print('#'*25)\n",
    "    print(f'### Fold {i+1}')\n",
    "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    # Instantiate the XGBRegressor model\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate = 0.1) # uses MSE to predict probabilities\n",
    "\n",
    "    model = MultiOutputRegressor(xgb_model) # since we have multiple outputs\n",
    "\n",
    "    \n",
    "    # Prepare training and validation data\n",
    "    TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
    "    X_train = train_scaled_df.loc[train_index]\n",
    "    y_train = train_labels_df.loc[train_index]\n",
    "\n",
    "    X_valid = train_scaled_df.loc[valid_index]\n",
    "    y_valid = train_labels_df.loc[valid_index]\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    # save model\n",
    "    joblib.dump(model, f\"/kaggle/working/multi_regressor_{i}.pkl\") \n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "\n",
    "    oof = y_pred / np.sum(y_pred, axis=1).reshape(-1,1) # ensure they sum to 1\n",
    "    #adjustment = 1 - np.sum(oof, axis=1)\n",
    "    #oof[:, 0] += adjustment\n",
    "    \n",
    "    true = y_valid.values\n",
    "\n",
    "    KL_divergence = np.mean(np.sum(true * (np.log(true + 1e-10) - np.log(oof + 1e-10)), axis=1))\n",
    "    print(\"KL divergence: \", KL_divergence)\n",
    "\n",
    "    \n",
    "    all_oof.append(oof)\n",
    "    all_true.append(true)\n",
    "    \n",
    "    del X_train, y_train, X_valid, y_valid, oof\n",
    "    gc.collect()\n",
    "    \n",
    "all_oof = np.concatenate(all_oof)\n",
    "all_true = np.concatenate(all_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3303b6a6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:20.563094Z",
     "iopub.status.busy": "2024-03-14T15:35:20.562791Z",
     "iopub.status.idle": "2024-03-14T15:35:20.587206Z",
     "shell.execute_reply": "2024-03-14T15:35:20.586252Z"
    },
    "papermill": {
     "duration": 0.050188,
     "end_time": "2024-03-14T15:35:20.589103",
     "exception": false,
     "start_time": "2024-03-14T15:35:20.538915",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "print('Test shape',test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3c5ae0a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:20.636343Z",
     "iopub.status.busy": "2024-03-14T15:35:20.636073Z",
     "iopub.status.idle": "2024-03-14T15:35:32.514964Z",
     "shell.execute_reply": "2024-03-14T15:35:32.514033Z"
    },
    "papermill": {
     "duration": 11.904643,
     "end_time": "2024-03-14T15:35:32.516953",
     "exception": false,
     "start_time": "2024-03-14T15:35:20.612310",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n",
      "Use Multi GPU 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataParallel(\n",
       "  (module): AE(\n",
       "    (encoder): Sequential(\n",
       "      (0): Linear(in_features=24000, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=2048, out_features=400, bias=True)\n",
       "      (7): ReLU()\n",
       "    )\n",
       "    (decoder): Sequential(\n",
       "      (0): Linear(in_features=400, out_features=2048, bias=True)\n",
       "      (1): ReLU()\n",
       "      (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (3): ReLU()\n",
       "      (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "      (5): ReLU()\n",
       "      (6): Linear(in_features=2048, out_features=24000, bias=True)\n",
       "      (7): Sigmoid()\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load model alpha from memory:\n",
    "model_alpha = AE(alpha_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_alpha.to(device)\n",
    "    model_alpha = nn.DataParallel(module=model_alpha)\n",
    "    print('Use Multi GPU', device)\n",
    "model_alpha.load_state_dict(torch.load(ALPHA_PATH))\n",
    "model_alpha.eval()\n",
    "\n",
    "# load model beta from memory:\n",
    "model_beta = AE(beta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_beta.to(device)\n",
    "    model_beta = nn.DataParallel(module=model_beta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_beta.load_state_dict(torch.load(BETA_PATH))\n",
    "model_beta.eval()\n",
    "\n",
    "# load model delta from memory:\n",
    "model_delta = AE(delta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_delta.to(device)\n",
    "    model_delta = nn.DataParallel(module=model_delta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_delta.load_state_dict(torch.load(DELTA_PATH))\n",
    "model_delta.eval()\n",
    "\n",
    "# load model theta from memory:\n",
    "model_theta = AE(theta_frequencies, 300, numFeatures=numFeatures)\n",
    "if torch.cuda.device_count() > 1:\n",
    "    device = torch.cuda.current_device()\n",
    "    model_theta.to(device)\n",
    "    model_theta = nn.DataParallel(module=model_theta)\n",
    "    print('Use Multi GPU', device)\n",
    "model_theta.load_state_dict(torch.load(THETA_PATH))\n",
    "model_theta.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c439af8c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:32.565596Z",
     "iopub.status.busy": "2024-03-14T15:35:32.565286Z",
     "iopub.status.idle": "2024-03-14T15:35:43.282239Z",
     "shell.execute_reply": "2024-03-14T15:35:43.281242Z"
    },
    "papermill": {
     "duration": 10.743424,
     "end_time": "2024-03-14T15:35:43.284394",
     "exception": false,
     "start_time": "2024-03-14T15:35:32.540970",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use device:  cpu\n",
      "Use device:  cpu\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AEW(\n",
       "  (encoder): Sequential(\n",
       "    (0): Linear(in_features=4000, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=400, bias=True)\n",
       "    (7): ReLU()\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Linear(in_features=400, out_features=2048, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=2048, out_features=2048, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=2048, out_features=4000, bias=True)\n",
       "    (7): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device_window = torch.device('cpu')\n",
    "\n",
    "# load model 10min from memory:\n",
    "model_10min = AEW(SPEC_FREQS, 300, numFeatures=numFeatures)\n",
    "model_10min = model_10min.to(device_window)\n",
    "print('Use device: ', device_window)\n",
    "model_10min.load_state_dict(torch.load(TEN_MIN_PATH))\n",
    "model_10min.eval()\n",
    "\n",
    "# load model 20sec from memory:\n",
    "model_20sec = AEW(SPEC_FREQS, 10, numFeatures=numFeatures)\n",
    "model_20sec = model_20sec.to(device_window)\n",
    "print('Use device: ', device_window)\n",
    "model_20sec.load_state_dict(torch.load(TWENTY_SEC_PATH))\n",
    "model_20sec.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c38ac2e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:43.335334Z",
     "iopub.status.busy": "2024-03-14T15:35:43.335033Z",
     "iopub.status.idle": "2024-03-14T15:35:43.721216Z",
     "shell.execute_reply": "2024-03-14T15:35:43.720083Z"
    },
    "papermill": {
     "duration": 0.413603,
     "end_time": "2024-03-14T15:35:43.723528",
     "exception": false,
     "start_time": "2024-03-14T15:35:43.309925",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 0 ns, total: 3 Âµs\n",
      "Wall time: 6.44 Âµs\n",
      "reading spectrograms from /kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms\n",
      "Generating 2400 features on 1 datapoints\n",
      "batch  0... New test shape:  (1, 2400)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get Feature Data\n",
    "\"\"\"\n",
    "%time\n",
    "# ENGINEER FEATURES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "batch_size = 32\n",
    "TEST_FEATURES = FEATURES\n",
    "\n",
    "spectrogram_dataset = SpectrogramDataset(\"test\", csv_file=\"/kaggle/input/hms-harmful-brain-activity-classification/test.csv\",\n",
    "                                         root_dir=\"/kaggle/input/hms-harmful-brain-activity-classification\", \n",
    "                                         transform=transforms.Compose([\n",
    "                                            Impute(), LogTransform()])\n",
    "                                        )\n",
    "\n",
    "dataloader = DataLoader(spectrogram_dataset, batch_size=batch_size,\n",
    "                        shuffle=False, num_workers=1)\n",
    "\n",
    "    \n",
    "print(f\"Generating {6 * numFeatures} features on {len(spectrogram_dataset)} datapoints\")\n",
    "\n",
    "\n",
    "# test data\n",
    "data = np.zeros((len(spectrogram_dataset), len(TEST_FEATURES)))\n",
    "\n",
    "for k, batch in enumerate(dataloader):\n",
    "    print(\"batch \", k, end=\"... \")\n",
    "    b_size = batch[\"values\"].shape[0] # this batch's size may be different from batch_size (mainly for last batch)\n",
    "    \n",
    "    \n",
    "    for i, eeg_segment in enumerate(batch[\"values\"]):\n",
    "        \n",
    "        signals = {\n",
    "            \"Alpha\": [], \"Beta\": [], \"Delta\": [], \"Theta\": []\n",
    "        }\n",
    "    \n",
    "        signals = extract_frequency_band_features(eeg_segment)\n",
    "            \n",
    "        vals = signals[\"Alpha\"]\n",
    "        if len(vals) == alpha_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_alpha.module.encoder(torch.tensor([norm_vals], dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 0:numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Beta\"]\n",
    "        if len(vals) == beta_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_beta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, numFeatures:2*numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Delta\"]\n",
    "        if len(vals) == delta_frequencies * 300:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_delta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 2*numFeatures:3*numFeatures] = x\n",
    "        \n",
    "        vals = signals[\"Theta\"]\n",
    "        if len(vals) == theta_frequencies * 300 * 4:\n",
    "            norm_vals = (vals - vals.min()) / (vals.max() - vals.min())\n",
    "            x = np.array(model_theta.module.encoder(torch.tensor(np.array(norm_vals).reshape(1,-1), dtype=torch.float32).to(device)).tolist())\n",
    "        else:\n",
    "            x = np.array([0 for i in range(numFeatures)])\n",
    "        data[k*batch_size + i, 3*numFeatures:4*numFeatures] = x\n",
    "        \n",
    "        # 10 MINUTE WINDOW FEATURES\n",
    "        raw_values_10min = eeg_segment.flatten()\n",
    "        normalized_values_10min = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "        x = np.array(model_10min.encoder(torch.tensor(np.array(normalized_values_10min).reshape(1,-1), dtype=torch.float32).to(device_window)).tolist())    \n",
    "        data[k*batch_size + i,4*numFeatures:5*numFeatures] = x\n",
    "\n",
    "        # 20 SECOND WINDOW FEATURES\n",
    "        raw_values_20sec = eeg_segment[145:155].flatten()\n",
    "        normalized_values_20sec = (raw_values_20sec - raw_values_20sec.min()) / (raw_values_20sec.max() - raw_values_20sec.min())\n",
    "        x = np.array(model_20sec.encoder(torch.tensor(np.array(normalized_values_20sec).reshape(1,-1), dtype=torch.float32).to(device_window)).tolist())\n",
    "        data[k*batch_size + i,5*numFeatures:6*numFeatures] = x    \n",
    "\n",
    "\n",
    "print('New test shape: ', data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c227f3d4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:43.773444Z",
     "iopub.status.busy": "2024-03-14T15:35:43.773127Z",
     "iopub.status.idle": "2024-03-14T15:35:43.890967Z",
     "shell.execute_reply": "2024-03-14T15:35:43.890254Z"
    },
    "papermill": {
     "duration": 0.144723,
     "end_time": "2024-03-14T15:35:43.892800",
     "exception": false,
     "start_time": "2024-03-14T15:35:43.748077",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del model_alpha, model_beta, model_delta, model_theta, model_10min, model_20sec\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dadfd220",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:43.941852Z",
     "iopub.status.busy": "2024-03-14T15:35:43.941573Z",
     "iopub.status.idle": "2024-03-14T15:35:43.959532Z",
     "shell.execute_reply": "2024-03-14T15:35:43.958798Z"
    },
    "papermill": {
     "duration": 0.044522,
     "end_time": "2024-03-14T15:35:43.961325",
     "exception": false,
     "start_time": "2024-03-14T15:35:43.916803",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Fit the scaler to the features and transform them\n",
    "features_scaled = scaler.transform(data)\n",
    "\n",
    "# Create a DataFrame from the scaled features\n",
    "test_scaled_df = pd.DataFrame(features_scaled)\n",
    "\n",
    "test_scaled_df.to_csv(\"/kaggle/working/test_scaled.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fb352d8a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:44.010422Z",
     "iopub.status.busy": "2024-03-14T15:35:44.010151Z",
     "iopub.status.idle": "2024-03-14T15:35:53.295411Z",
     "shell.execute_reply": "2024-03-14T15:35:53.294236Z"
    },
    "papermill": {
     "duration": 9.314143,
     "end_time": "2024-03-14T15:35:53.299527",
     "exception": false,
     "start_time": "2024-03-14T15:35:43.985384",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 1 , 2 , 3 , 4 , \n",
      "Test preds shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "# INFER XGBOOST ON TEST\n",
    "preds = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(i, ', ', end='')\n",
    "    \n",
    "    # Load the model\n",
    "    model = joblib.load(f\"multi_regressor_{i}.pkl\")\n",
    "\n",
    "    # Make predictions\n",
    "    pred = model.predict(test_scaled_df)\n",
    "    pred[pred<0] = 0\n",
    "    pred = pred / np.sum(pred, axis=1).reshape(-1,1) # ensure they sum to 1\n",
    "#     adjustment = 1 - np.sum(pred, axis=1)\n",
    "#     pred[:, 0] += adjustment\n",
    "    \n",
    "    preds.append(pred)\n",
    "    \n",
    "\n",
    "# Average the predictions from each fold\n",
    "pred = np.mean(preds, axis=0)\n",
    "print()\n",
    "print('Test preds shape', pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99dc84ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:53.355882Z",
     "iopub.status.busy": "2024-03-14T15:35:53.355600Z",
     "iopub.status.idle": "2024-03-14T15:35:53.372522Z",
     "shell.execute_reply": "2024-03-14T15:35:53.371665Z"
    },
    "papermill": {
     "duration": 0.045811,
     "end_time": "2024-03-14T15:35:53.374412",
     "exception": false,
     "start_time": "2024-03-14T15:35:53.328601",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.15119</td>\n",
       "      <td>0.045008</td>\n",
       "      <td>0.002161</td>\n",
       "      <td>0.161519</td>\n",
       "      <td>0.020744</td>\n",
       "      <td>0.619378</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283       0.15119  0.045008  0.002161   0.161519   0.020744   \n",
       "\n",
       "   other_vote  \n",
       "0    0.619378  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TARGETS = ['seizure_vote', 'lpd_vote','gpd_vote','lrda_vote','grda_vote','other_vote']\n",
    "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub[TARGETS] = pred\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "print('Submission shape',sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ad83a33b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-14T15:35:53.424255Z",
     "iopub.status.busy": "2024-03-14T15:35:53.424014Z",
     "iopub.status.idle": "2024-03-14T15:35:53.431396Z",
     "shell.execute_reply": "2024-03-14T15:35:53.430631Z"
    },
    "papermill": {
     "duration": 0.034475,
     "end_time": "2024-03-14T15:35:53.433272",
     "exception": false,
     "start_time": "2024-03-14T15:35:53.398797",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "sub.iloc[:,-6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b647815",
   "metadata": {
    "papermill": {
     "duration": 0.024295,
     "end_time": "2024-03-14T15:35:53.482090",
     "exception": false,
     "start_time": "2024-03-14T15:35:53.457795",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4572183,
     "sourceId": 7842202,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4568961,
     "sourceId": 7842221,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4597683,
     "sourceId": 7842243,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4597692,
     "sourceId": 7842258,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4598946,
     "sourceId": 7843919,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4598952,
     "sourceId": 7843928,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": true,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2969.396219,
   "end_time": "2024-03-14T15:35:56.265781",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-14T14:46:26.869562",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
