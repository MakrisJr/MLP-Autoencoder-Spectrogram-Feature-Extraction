{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef8415dc",
   "metadata": {
    "papermill": {
     "duration": 0.017517,
     "end_time": "2024-02-27T21:13:57.817864",
     "exception": false,
     "start_time": "2024-02-27T21:13:57.800347",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>1 |</span></b> <b>INTRODUCTION</b></div>\n",
    "\n",
    "ðŸ‘‹ Welcome to \"ðŸ§ Exploring EEG: A Beginner's Guide\"! \n",
    "\n",
    "If you're fascinated by the wonders of the human brain and the intricate patterns of brainwaves, but find the world of Electroencephalography (EEG) analysis daunting, you're in the right place. \n",
    "\n",
    "This notebook is designed for beginners like me & you, aiming to demystify the complexities of EEG data and make your learning journey both enjoyable and informative.\n",
    "\n",
    "### <b><span style='color:#FFCE30'> 1.1 |</span> Intention of the notebook</b>\n",
    "In this notebook, we will embark on an exploratory journey into the realm of EEG data analysis. Our goal is to provide a clear, step-by-step guide to understanding and analyzing EEG signals, which are crucial in detecting and classifying brain activities, such as seizures. We aim to:\n",
    "\n",
    "* Break down complex concepts into easily digestible sections.\n",
    "* Illustrate each step with practical code examples.\n",
    "* Reference public notebooks and discussions to enhance your learning experience.\n",
    "\n",
    "\n",
    "### <b><span style='color:#FFCE30'> 1.2 |</span> Learning Objective</b>\n",
    "By the end of this notebook, you will have a foundational understanding of:\n",
    "\n",
    "* The basics of EEG signals and their significance in medical research and neurology.\n",
    "* How to preprocess and analyze EEG data.\n",
    "* Run through the basic code to build a machine learning model for EEG data classification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c33d8a",
   "metadata": {
    "papermill": {
     "duration": 0.012637,
     "end_time": "2024-02-27T21:13:57.843798",
     "exception": false,
     "start_time": "2024-02-27T21:13:57.831161",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>2 |</span></b> <b>REFERENCE & ACKNOWLEDGEMENT</b></div>\n",
    "\n",
    "This notebook wouldn't be possible without the valuable insights and contributions from the Kaggle community. I've leveraged several resources to compile the most effective learning path for us:\n",
    "\n",
    "* https://www.kaggle.com/code/cdeotte/catboost-starter-lb-0-8\n",
    "* https://www.kaggle.com/code/mvvppp/hms-eda-and-domain-journey\n",
    "* https://www.kaggle.com/code/ksooklall/hms-banana-montage\n",
    "* https://www.kaggle.com/code/mpwolke/seizures-classification-parquet\n",
    "\n",
    "\n",
    "Feel free to explore these resources alongside this notebook to deepen your understanding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cb8268c",
   "metadata": {
    "papermill": {
     "duration": 0.012639,
     "end_time": "2024-02-27T21:13:57.869430",
     "exception": false,
     "start_time": "2024-02-27T21:13:57.856791",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>3 |</span></b> <b>LOAD LIBARIES</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "23d216f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:13:57.897924Z",
     "iopub.status.busy": "2024-02-27T21:13:57.896852Z",
     "iopub.status.idle": "2024-02-27T21:13:58.867765Z",
     "shell.execute_reply": "2024-02-27T21:13:58.866704Z"
    },
    "papermill": {
     "duration": 0.98823,
     "end_time": "2024-02-27T21:13:58.870633",
     "exception": false,
     "start_time": "2024-02-27T21:13:57.882403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "VER = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caae6025",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T15:14:51.033378Z",
     "iopub.status.busy": "2024-01-14T15:14:51.032997Z",
     "iopub.status.idle": "2024-01-14T15:14:51.038874Z",
     "shell.execute_reply": "2024-01-14T15:14:51.037454Z",
     "shell.execute_reply.started": "2024-01-14T15:14:51.033348Z"
    },
    "papermill": {
     "duration": 0.013388,
     "end_time": "2024-02-27T21:13:58.897893",
     "exception": false,
     "start_time": "2024-02-27T21:13:58.884505",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>4 |</span></b> <b>INTRODUCTION TO EEG AND SEIZURE DETECTION</b></div>\n",
    "\n",
    "<b><span style='color:#FFCE30'> 4.1 |</span> Electroencephalography (EEG) - The Window into Brain Activity</b>\n",
    "\n",
    "* Electroencephalography, commonly known as EEG, is a non-invasive method used by medical professionals to record electrical activity in the brain. \n",
    "* This is done using electrodes placed along the scalp. \n",
    "* EEG is a crucial tool in diagnosing neurological disorders, especially epilepsy, which is characterized by recurrent seizures.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Sebastian-Nagel-4/publication/338423585/figure/fig1/AS:844668573073409@1578396089381/Sketch-of-how-to-record-an-Electroencephalogram-An-EEG-allows-measuring-the-electrical.png\" alt=\"EEG\" width=\"600\" height=\"400\">\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98dcb2ef",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:13:58.927342Z",
     "iopub.status.busy": "2024-02-27T21:13:58.926808Z",
     "iopub.status.idle": "2024-02-27T21:13:59.819313Z",
     "shell.execute_reply": "2024-02-27T21:13:59.818109Z"
    },
    "papermill": {
     "duration": 0.910459,
     "end_time": "2024-02-27T21:13:59.822359",
     "exception": false,
     "start_time": "2024-02-27T21:13:58.911900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Fp1</th>\n",
       "      <th>F3</th>\n",
       "      <th>C3</th>\n",
       "      <th>P3</th>\n",
       "      <th>F7</th>\n",
       "      <th>T3</th>\n",
       "      <th>T5</th>\n",
       "      <th>O1</th>\n",
       "      <th>Fz</th>\n",
       "      <th>Cz</th>\n",
       "      <th>Pz</th>\n",
       "      <th>Fp2</th>\n",
       "      <th>F4</th>\n",
       "      <th>C4</th>\n",
       "      <th>P4</th>\n",
       "      <th>F8</th>\n",
       "      <th>T4</th>\n",
       "      <th>T6</th>\n",
       "      <th>O2</th>\n",
       "      <th>EKG</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-105.849998</td>\n",
       "      <td>-89.230003</td>\n",
       "      <td>-79.459999</td>\n",
       "      <td>-49.230000</td>\n",
       "      <td>-99.730003</td>\n",
       "      <td>-87.769997</td>\n",
       "      <td>-53.330002</td>\n",
       "      <td>-50.740002</td>\n",
       "      <td>-32.250000</td>\n",
       "      <td>-42.099998</td>\n",
       "      <td>-43.270000</td>\n",
       "      <td>-88.730003</td>\n",
       "      <td>-74.410004</td>\n",
       "      <td>-92.459999</td>\n",
       "      <td>-58.930000</td>\n",
       "      <td>-75.739998</td>\n",
       "      <td>-59.470001</td>\n",
       "      <td>8.210000</td>\n",
       "      <td>66.489998</td>\n",
       "      <td>1404.930054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-85.470001</td>\n",
       "      <td>-75.070000</td>\n",
       "      <td>-60.259998</td>\n",
       "      <td>-38.919998</td>\n",
       "      <td>-73.080002</td>\n",
       "      <td>-87.510002</td>\n",
       "      <td>-39.680000</td>\n",
       "      <td>-35.630001</td>\n",
       "      <td>-76.839996</td>\n",
       "      <td>-62.740002</td>\n",
       "      <td>-43.040001</td>\n",
       "      <td>-68.629997</td>\n",
       "      <td>-61.689999</td>\n",
       "      <td>-69.320000</td>\n",
       "      <td>-35.790001</td>\n",
       "      <td>-58.900002</td>\n",
       "      <td>-41.660000</td>\n",
       "      <td>196.190002</td>\n",
       "      <td>230.669998</td>\n",
       "      <td>3402.669922</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.840000</td>\n",
       "      <td>34.849998</td>\n",
       "      <td>56.430000</td>\n",
       "      <td>67.970001</td>\n",
       "      <td>48.099998</td>\n",
       "      <td>25.350000</td>\n",
       "      <td>80.250000</td>\n",
       "      <td>48.060001</td>\n",
       "      <td>6.720000</td>\n",
       "      <td>37.880001</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>16.580000</td>\n",
       "      <td>55.060001</td>\n",
       "      <td>45.020000</td>\n",
       "      <td>70.529999</td>\n",
       "      <td>47.820000</td>\n",
       "      <td>72.029999</td>\n",
       "      <td>-67.180000</td>\n",
       "      <td>-171.309998</td>\n",
       "      <td>-3565.800049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-56.320000</td>\n",
       "      <td>-37.279999</td>\n",
       "      <td>-28.100000</td>\n",
       "      <td>-2.820000</td>\n",
       "      <td>-43.430000</td>\n",
       "      <td>-35.049999</td>\n",
       "      <td>3.910000</td>\n",
       "      <td>-12.660000</td>\n",
       "      <td>8.650000</td>\n",
       "      <td>3.830000</td>\n",
       "      <td>4.180000</td>\n",
       "      <td>-51.900002</td>\n",
       "      <td>-21.889999</td>\n",
       "      <td>-41.330002</td>\n",
       "      <td>-11.580000</td>\n",
       "      <td>-27.040001</td>\n",
       "      <td>-11.730000</td>\n",
       "      <td>-91.000000</td>\n",
       "      <td>-81.190002</td>\n",
       "      <td>-1280.930054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-110.139999</td>\n",
       "      <td>-104.519997</td>\n",
       "      <td>-96.879997</td>\n",
       "      <td>-70.250000</td>\n",
       "      <td>-111.660004</td>\n",
       "      <td>-114.430000</td>\n",
       "      <td>-71.830002</td>\n",
       "      <td>-61.919998</td>\n",
       "      <td>-76.150002</td>\n",
       "      <td>-79.779999</td>\n",
       "      <td>-67.480003</td>\n",
       "      <td>-99.029999</td>\n",
       "      <td>-93.610001</td>\n",
       "      <td>-104.410004</td>\n",
       "      <td>-70.070000</td>\n",
       "      <td>-89.250000</td>\n",
       "      <td>-77.260002</td>\n",
       "      <td>155.729996</td>\n",
       "      <td>264.850006</td>\n",
       "      <td>4325.370117</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Fp1          F3         C3         P3          F7          T3  \\\n",
       "0 -105.849998  -89.230003 -79.459999 -49.230000  -99.730003  -87.769997   \n",
       "1  -85.470001  -75.070000 -60.259998 -38.919998  -73.080002  -87.510002   \n",
       "2    8.840000   34.849998  56.430000  67.970001   48.099998   25.350000   \n",
       "3  -56.320000  -37.279999 -28.100000  -2.820000  -43.430000  -35.049999   \n",
       "4 -110.139999 -104.519997 -96.879997 -70.250000 -111.660004 -114.430000   \n",
       "\n",
       "          T5         O1         Fz         Cz         Pz        Fp2  \\\n",
       "0 -53.330002 -50.740002 -32.250000 -42.099998 -43.270000 -88.730003   \n",
       "1 -39.680000 -35.630001 -76.839996 -62.740002 -43.040001 -68.629997   \n",
       "2  80.250000  48.060001   6.720000  37.880001  61.000000  16.580000   \n",
       "3   3.910000 -12.660000   8.650000   3.830000   4.180000 -51.900002   \n",
       "4 -71.830002 -61.919998 -76.150002 -79.779999 -67.480003 -99.029999   \n",
       "\n",
       "          F4          C4         P4         F8         T4          T6  \\\n",
       "0 -74.410004  -92.459999 -58.930000 -75.739998 -59.470001    8.210000   \n",
       "1 -61.689999  -69.320000 -35.790001 -58.900002 -41.660000  196.190002   \n",
       "2  55.060001   45.020000  70.529999  47.820000  72.029999  -67.180000   \n",
       "3 -21.889999  -41.330002 -11.580000 -27.040001 -11.730000  -91.000000   \n",
       "4 -93.610001 -104.410004 -70.070000 -89.250000 -77.260002  155.729996   \n",
       "\n",
       "           O2          EKG  \n",
       "0   66.489998  1404.930054  \n",
       "1  230.669998  3402.669922  \n",
       "2 -171.309998 -3565.800049  \n",
       "3  -81.190002 -1280.930054  \n",
       "4  264.850006  4325.370117  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the reading of one parquet for understanding\n",
    "\n",
    "BASE_PATH = '/kaggle/input/hms-harmful-brain-activity-classification/'\n",
    "\n",
    "df = pd.DataFrame({'path': glob(BASE_PATH + '**/*.parquet')})\n",
    "df['test_type'] = df['path'].str.split('/').str.get(-2).str.split('_').str.get(-1)\n",
    "df['id'] = df['path'].str.split('/').str.get(-1).str.split('.').str.get(0)\n",
    "\n",
    "df_eeg = pd.read_parquet(BASE_PATH + 'train_eegs/1000913311.parquet')\n",
    "df_eeg.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a8518d56",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:13:59.853894Z",
     "iopub.status.busy": "2024-02-27T21:13:59.853497Z",
     "iopub.status.idle": "2024-02-27T21:13:59.859475Z",
     "shell.execute_reply": "2024-02-27T21:13:59.858714Z"
    },
    "papermill": {
     "duration": 0.023858,
     "end_time": "2024-02-27T21:13:59.861597",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.837739",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determine the number of channels\n",
    "# Assuming each row is a time point and each column is a channel\n",
    "n_channels = df_eeg.shape[1]\n",
    "n_channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6b4c506",
   "metadata": {
    "papermill": {
     "duration": 0.013145,
     "end_time": "2024-02-27T21:13:59.888466",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.875321",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "* The headers in the dataset (Fp1, F3, C3, P3, F7, T3, T5, O1, Fz, Cz, Pz, Fp2, F4, C4, P4, F8, T4, T6, O2, EKG) are standard electrode placement labels used in electroencephalography (EEG). \n",
    "* These labels correspond to specific positions on the scalp where EEG electrodes are placed to record brain activity. \n",
    "* Here's a brief overview of what they represent:\n",
    "\n",
    "1. **Fp1, Fp2:** Frontopolar electrodes, located on the forehead, left and right side.\n",
    "2. **F3, F4:** Frontal electrodes, on the left and right side of the forehead.\n",
    "3. **C3, C4:** Central electrodes, placed above the left and right hemispheres of the brain.\n",
    "4. **P3, P4:** Parietal electrodes, located on the upper back portion of the head, left and right sides.\n",
    "5. **O1, O2:** Occipital electrodes, positioned at the back of the head near the visual cortex.\n",
    "6. **T3, T4, T5, T6:** Temporal electrodes, situated on the left and right sides of the head near the ears. They are often involved in monitoring auditory functions.\n",
    "7. **F7, F8:** Frontal-temporal electrodes, located at the front of the temporal lobes.\n",
    "8. **Fz, Cz, Pz:** Midline electrodes, located at the frontal (Fz), central (Cz), and parietal (Pz) positions on the midline of the head.\n",
    "9. **EKG:** Electrocardiogram electrode, which records the heartâ€™s electrical activity. It's not directly related to brain activity but can be important in some EEG analyses.\n",
    "\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Danny-Plass-Oude-Bos/publication/237777779/figure/fig3/AS:669556259434497@1536646060035/10-20-system-of-electrode-placement.png\" alt=\"10-20-system-of-electrode-placement\" width=\"300\" height=\"150\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc88c886",
   "metadata": {
    "papermill": {
     "duration": 0.013146,
     "end_time": "2024-02-27T21:13:59.915032",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.901886",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<b><span style='color:#FFCE30'> 4.2 |</span> Seizures and Their Impact</b>\n",
    "* Seizures are sudden, uncontrolled electrical disturbances in the brain that can cause changes in behavior, feelings, movements, and levels of consciousness. \n",
    "* Detecting and classifying seizures accurately is vital for appropriate treatment and care, especially in critically ill patients.\n",
    "\n",
    "<b><span style='color:#FFCE30'> 4.3 |</span> The Challenge of Manual EEG Analysis</b>\n",
    "\n",
    "* Traditionally, EEG data analysis relies on visual inspection by trained neurologists. \n",
    "* This process is not only time-consuming and labor-intensive but also prone to errors due to fatigue and subjective interpretation.\n",
    "\n",
    "<img src=\"https://slideplayer.com/slide/12925171/78/images/2/Manual+Interpretation+of+EEGs.jpg\" alt=\"Manual Interpretation of EEG\" width=\"700\" height=\"300\">\n",
    "Source: Automated Identification of Abnormal Adult EEG, S. LÃ³pez, G. Suarez, D. Jungreis, I. Obeid and J. Picone, Neural Engineering Data Consortium, Temple University\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5dd86",
   "metadata": {
    "papermill": {
     "duration": 0.01307,
     "end_time": "2024-02-27T21:13:59.941597",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.928527",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<b><span style='color:#FFCE30'> 4.4 |</span> The Role of Data Science in EEG Analysis</b>\n",
    "\n",
    "* Automating EEG Interpretation\n",
    "The advent of machine learning and data science offers an opportunity to automate the interpretation of EEG data. By developing algorithms that can detect and classify different patterns in EEG signals, we can aid neurologists in making faster, more accurate diagnoses.\n",
    "\n",
    "* The Data Science Approach\n",
    "Data scientists approach this challenge by first preprocessing the EEG data, which involves filtering out noise and extracting relevant features. Machine learning models are then trained on these features to distinguish between different types of brain activity.\n",
    "\n",
    "<img src=\"https://www.researchgate.net/profile/Huiguang-He/publication/336336651/figure/fig1/AS:834361356197888@1575938657076/The-flow-chart-of-EEG-emotion-classification-with-similarity-learning-network.png\" alt=\"flowchart for EEG classification\" width=\"700\" height=\"300\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa85ab88",
   "metadata": {
    "papermill": {
     "duration": 0.013218,
     "end_time": "2024-02-27T21:13:59.968961",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.955743",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<b><span style='color:#FFCE30'> 4.5 |</span> Understanding EEG Patterns</b>\n",
    "\n",
    "In the realm of EEG analysis for seizure detection, certain patterns are of particular interest:\n",
    "\n",
    "1. **Seizure (SZ):** Characterized by abnormal rhythmic activity, indicative of a seizure.\n",
    "2. **Generalized Periodic Discharges (GPD):** Patterns that may be seen in various encephalopathies.\n",
    "3. **Lateralized Periodic Discharges (LPD):** Often associated with focal brain lesions.\n",
    "4. **Lateralized Rhythmic Delta Activity (LRDA):** Can be observed in focal brain dysfunction.\n",
    "5. **Generalized Rhythmic Delta Activity (GRDA):** Typically related to diffuse brain dysfunction.\n",
    "6. **\"Other\" Patterns:** Any other type of activity not falling into the above categories.\n",
    "\n",
    "<b><span style='color:#FFCE30'> 4.6 |</span> Interpreting Complex EEG Data</b>\n",
    "\n",
    "EEG data interpretation can be complex, especially in edge cases where expert neurologists may not agree on a classification. This is where machine learning models can particularly shine by providing an additional layer of analysis.\n",
    "\n",
    "<img src=\"https://www.neurology.org/cms/10.1212/WNL.0000000000207127/asset/bd84c182-712c-41ab-8742-cecf9d49a322/assets/images/large/5ff2.jpg\" alt=\"flowchart for EEG classification\" width=\"700\" height=\"300\">\n",
    "\n",
    "Source: Development of Expert-Level Classification of Seizures and Rhythmic and Periodic Patterns During EEG Interpretation https://www.neurology.org/doi/10.1212/WNL.0000000000207127\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a2378c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T15:16:07.035699Z",
     "iopub.status.busy": "2024-01-14T15:16:07.035029Z",
     "iopub.status.idle": "2024-01-14T15:16:07.040799Z",
     "shell.execute_reply": "2024-01-14T15:16:07.039623Z",
     "shell.execute_reply.started": "2024-01-14T15:16:07.035656Z"
    },
    "papermill": {
     "duration": 0.013154,
     "end_time": "2024-02-27T21:13:59.995750",
     "exception": false,
     "start_time": "2024-02-27T21:13:59.982596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>5 |</span></b> <b>LOAD TRAIN DATA</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34ad4aa9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:14:00.025100Z",
     "iopub.status.busy": "2024-02-27T21:14:00.024696Z",
     "iopub.status.idle": "2024-02-27T21:14:00.332327Z",
     "shell.execute_reply": "2024-02-27T21:14:00.331126Z"
    },
    "papermill": {
     "duration": 0.32491,
     "end_time": "2024-02-27T21:14:00.334871",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.009961",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train shape: (106800, 15)\n",
      "Targets ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>eeg_sub_id</th>\n",
       "      <th>eeg_label_offset_seconds</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>spectrogram_sub_id</th>\n",
       "      <th>spectrogram_label_offset_seconds</th>\n",
       "      <th>label_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>expert_consensus</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>127492639</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0</td>\n",
       "      <td>3887563113</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>2</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1142670488</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>3</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2718991173</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1628180742</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>353733</td>\n",
       "      <td>4</td>\n",
       "      <td>24.0</td>\n",
       "      <td>3080632009</td>\n",
       "      <td>42516</td>\n",
       "      <td>Seizure</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  eeg_sub_id  eeg_label_offset_seconds  spectrogram_id  \\\n",
       "0  1628180742           0                       0.0          353733   \n",
       "1  1628180742           1                       6.0          353733   \n",
       "2  1628180742           2                       8.0          353733   \n",
       "3  1628180742           3                      18.0          353733   \n",
       "4  1628180742           4                      24.0          353733   \n",
       "\n",
       "   spectrogram_sub_id  spectrogram_label_offset_seconds    label_id  \\\n",
       "0                   0                               0.0   127492639   \n",
       "1                   1                               6.0  3887563113   \n",
       "2                   2                               8.0  1142670488   \n",
       "3                   3                              18.0  2718991173   \n",
       "4                   4                              24.0  3080632009   \n",
       "\n",
       "   patient_id expert_consensus  seizure_vote  lpd_vote  gpd_vote  lrda_vote  \\\n",
       "0       42516          Seizure             3         0         0          0   \n",
       "1       42516          Seizure             3         0         0          0   \n",
       "2       42516          Seizure             3         0         0          0   \n",
       "3       42516          Seizure             3         0         0          0   \n",
       "4       42516          Seizure             3         0         0          0   \n",
       "\n",
       "   grda_vote  other_vote  \n",
       "0          0           0  \n",
       "1          0           0  \n",
       "2          0           0  \n",
       "3          0           0  \n",
       "4          0           0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/train.csv')\n",
    "TARGETS = df.columns[-6:]\n",
    "print('Train shape:', df.shape )\n",
    "print('Targets', list(TARGETS))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7911ccf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T15:17:26.898867Z",
     "iopub.status.busy": "2024-01-14T15:17:26.898038Z",
     "iopub.status.idle": "2024-01-14T15:17:26.903917Z",
     "shell.execute_reply": "2024-01-14T15:17:26.902565Z",
     "shell.execute_reply.started": "2024-01-14T15:17:26.898818Z"
    },
    "papermill": {
     "duration": 0.02198,
     "end_time": "2024-02-27T21:14:00.375371",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.353391",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>6 |</span></b> <b>CREATE NON-OVERLAPPING EEG ID TRAIN DATA</b></div>\n",
    "\n",
    "Following the notebook from Chris Deotte: https://www.kaggle.com/code/cdeotte/catboost-starter-lb-0-8,\n",
    "Initial discussion found here https://www.kaggle.com/competitions/hms-harmful-brain-activity-classification/discussion/467021\n",
    "\n",
    "We perform the following because:\n",
    "\n",
    "* **Match Training Data with Test Data Format:** The competition states that the test data does not have multiple segments from the same eeg_id. To make the training data similar to the test data, we also use only one segment per eeg_id in the training data.\n",
    "\n",
    "* **Remove Redundancies:** This approach ensures that the training data does not have overlapping or redundant information, which can lead to a more accurate and generalizable machine learning model.\n",
    "\n",
    "* **Consistency in Data:** By standardizing how we handle the EEG segments in training, we ensure that our model learns from data that is consistent in format with the data it will be tested on.\n",
    "\n",
    "* **Data Preparation for Machine Learning:** The normalization of target variables and inclusion of relevant features like patient_id and expert_consensus prepare the dataset for effective machine learning modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40b1bdb2",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:14:00.412328Z",
     "iopub.status.busy": "2024-02-27T21:14:00.411703Z",
     "iopub.status.idle": "2024-02-27T21:14:00.529839Z",
     "shell.execute_reply": "2024-02-27T21:14:00.528625Z"
    },
    "papermill": {
     "duration": 0.141435,
     "end_time": "2024-02-27T21:14:00.532715",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.391280",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train non-overlapp eeg_id shape: (17089, 12)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>LPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   eeg_id     spec_id     min     max  patient_id  seizure_vote  lpd_vote  \\\n",
       "0  568657   789577333     0.0    16.0       20654           0.0  0.000000   \n",
       "1  582999  1552638400     0.0    38.0       20230           0.0  0.857143   \n",
       "2  642382    14960202  1008.0  1032.0        5955           0.0  0.000000   \n",
       "3  751790   618728447   908.0   908.0       38549           0.0  0.000000   \n",
       "4  778705    52296320     0.0     0.0       40955           0.0  0.000000   \n",
       "\n",
       "   gpd_vote  lrda_vote  grda_vote  other_vote target  \n",
       "0      0.25   0.000000   0.166667    0.583333  Other  \n",
       "1      0.00   0.071429   0.000000    0.071429    LPD  \n",
       "2      0.00   0.000000   0.000000    1.000000  Other  \n",
       "3      1.00   0.000000   0.000000    0.000000    GPD  \n",
       "4      0.00   0.000000   0.000000    1.000000  Other  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating a Unique EEG Segment per eeg_id:\n",
    "# The code groups (groupby) the EEG data (df) by eeg_id. Each eeg_id represents a different EEG recording.\n",
    "# It then picks the first spectrogram_id and the earliest (min) spectrogram_label_offset_seconds for each eeg_id. This helps in identifying the starting point of each EEG segment.\n",
    "# The resulting DataFrame train has columns spec_id (first spectrogram_id) and min (earliest spectrogram_label_offset_seconds).\n",
    "train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
    "train.columns = ['spec_id','min']\n",
    "\n",
    "\n",
    "# Finding the Latest Point in Each EEG Segment:\n",
    "# The code again groups the data by eeg_id and finds the latest (max) spectrogram_label_offset_seconds for each segment.\n",
    "# This max value is added to the train DataFrame, representing the end point of each EEG segment.\n",
    "tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "    {'spectrogram_label_offset_seconds':'max'})\n",
    "train['max'] = tmp\n",
    "\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['patient_id']].agg('first') # The code adds the patient_id for each eeg_id to the train DataFrame. This links each EEG segment to a specific patient.\n",
    "train['patient_id'] = tmp\n",
    "\n",
    "\n",
    "tmp = df.groupby('eeg_id')[TARGETS].agg('sum') # The code sums up the target variable counts (like votes for seizure, LPD, etc.) for each eeg_id.\n",
    "for t in TARGETS:\n",
    "    train[t] = tmp[t].values\n",
    "    \n",
    "y_data = train[TARGETS].values # It then normalizes these counts so that they sum up to 1. This step converts the counts into probabilities, which is a common practice in classification tasks.\n",
    "y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "train[TARGETS] = y_data\n",
    "\n",
    "tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first') # For each eeg_id, the code includes the expert_consensus on the EEG segment's classification.\n",
    "train['target'] = tmp\n",
    "\n",
    "train = train.reset_index() # This makes eeg_id a regular column, making the DataFrame easier to work with.\n",
    "print('Train non-overlapp eeg_id shape:', train.shape )\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "96f82412",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:14:00.565146Z",
     "iopub.status.busy": "2024-02-27T21:14:00.563887Z",
     "iopub.status.idle": "2024-02-27T21:14:00.588519Z",
     "shell.execute_reply": "2024-02-27T21:14:00.587254Z"
    },
    "papermill": {
     "duration": 0.043248,
     "end_time": "2024-02-27T21:14:00.591367",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.548119",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>147350182</td>\n",
       "      <td>1908433744</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>2615.0</td>\n",
       "      <td>17408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16281</th>\n",
       "      <td>4084934272</td>\n",
       "      <td>1908433744</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>2063.0</td>\n",
       "      <td>17408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16954</th>\n",
       "      <td>4255016832</td>\n",
       "      <td>1908433744</td>\n",
       "      <td>2783.0</td>\n",
       "      <td>2783.0</td>\n",
       "      <td>17408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17060</th>\n",
       "      <td>4285210475</td>\n",
       "      <td>1908433744</td>\n",
       "      <td>2845.0</td>\n",
       "      <td>2845.0</td>\n",
       "      <td>17408</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>GPD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           eeg_id     spec_id     min     max  patient_id  seizure_vote  \\\n",
       "564     147350182  1908433744  2615.0  2615.0       17408           0.0   \n",
       "16281  4084934272  1908433744  2063.0  2063.0       17408           0.0   \n",
       "16954  4255016832  1908433744  2783.0  2783.0       17408           0.0   \n",
       "17060  4285210475  1908433744  2845.0  2845.0       17408           0.0   \n",
       "\n",
       "       lpd_vote  gpd_vote  lrda_vote  grda_vote  other_vote target  \n",
       "564         0.0       1.0        0.0        0.0         0.0    GPD  \n",
       "16281       0.0       1.0        0.0        0.0         0.0    GPD  \n",
       "16954       0.0       1.0        0.0        0.0         0.0    GPD  \n",
       "17060       0.0       1.0        0.0        0.0         0.0    GPD  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[(train.spec_id == 1908433744) & (train['min'] // 1000 == 2)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd8ea1c",
   "metadata": {
    "papermill": {
     "duration": 0.014967,
     "end_time": "2024-02-27T21:14:00.621475",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.606508",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>7 |</span></b> <b>FEATURE ENGINEERING</b></div>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2657dccd",
   "metadata": {
    "papermill": {
     "duration": 0.016207,
     "end_time": "2024-02-27T21:14:00.715148",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.698941",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "<b><span style='color:#FFCE30'> 7.1 |</span> 10 min and 20 sec windows</b>\n",
    "\n",
    "* The code belows efficiently reads spectrogram data, from a single combined file, based on the set variable. We relied on the dataset by Chris Deotte to save time. https://www.kaggle.com/datasets/cdeotte/brain-spectrograms\n",
    "* It then performs feature engineering by calculating mean and minimum values over two different time windows for each frequency in the spectrogram.\n",
    "It produce produces in 1600 features (400 features Ã— 4 calculations) for each EEG ID.\n",
    "* The new features are intended to help the model better understand and classify the EEG data.\n",
    "* This approach is designed to enhance the model's performance by providing it with more detailed information derived from the spectrogram data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e416f5db",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:14:00.753435Z",
     "iopub.status.busy": "2024-02-27T21:14:00.752668Z",
     "iopub.status.idle": "2024-02-27T21:14:00.759118Z",
     "shell.execute_reply": "2024-02-27T21:14:00.757364Z"
    },
    "papermill": {
     "duration": 0.029658,
     "end_time": "2024-02-27T21:14:00.761909",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.732251",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "READ_SPEC_FILES = False # If READ_SPEC_FILES is False, the code reads the combined file instead of individual files.\n",
    "FEATURE_ENGINEER = True\n",
    "READ_EEG_SPEC_FILES = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "09e19e69",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:14:00.795705Z",
     "iopub.status.busy": "2024-02-27T21:14:00.794751Z",
     "iopub.status.idle": "2024-02-27T21:15:06.063412Z",
     "shell.execute_reply": "2024-02-27T21:15:06.062117Z"
    },
    "papermill": {
     "duration": 65.302513,
     "end_time": "2024-02-27T21:15:06.080359",
     "exception": false,
     "start_time": "2024-02-27T21:14:00.777846",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 11138 spectrogram parquets\n",
      "CPU times: user 4.38 s, sys: 11 s, total: 15.4 s\n",
      "Wall time: 1min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# READ ALL SPECTROGRAMS\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n",
    "files = os.listdir(PATH)\n",
    "print(f'There are {len(files)} spectrogram parquets')\n",
    "\n",
    "if READ_SPEC_FILES:    \n",
    "    spectrograms = {}\n",
    "    for i,f in enumerate(files):\n",
    "        if i%100==0: print(i,', ',end='')\n",
    "        tmp = pd.read_parquet(f'{PATH}{f}')\n",
    "        name = int(f.split('.')[0])\n",
    "        spectrograms[name] = tmp.iloc[:,1:].values\n",
    "else:\n",
    "    spectrograms = np.load('/kaggle/input/brain-spectrograms/specs.npy',allow_pickle=True).item()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "570c2894",
   "metadata": {
    "papermill": {
     "duration": 0.015066,
     "end_time": "2024-02-27T21:15:06.110871",
     "exception": false,
     "start_time": "2024-02-27T21:15:06.095805",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Autoencoder Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4877339",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:15:06.143441Z",
     "iopub.status.busy": "2024-02-27T21:15:06.142856Z",
     "iopub.status.idle": "2024-02-27T21:15:10.101522Z",
     "shell.execute_reply": "2024-02-27T21:15:10.100295Z"
    },
    "papermill": {
     "duration": 3.978392,
     "end_time": "2024-02-27T21:15:10.104631",
     "exception": false,
     "start_time": "2024-02-27T21:15:06.126239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import torch.nn.init as init\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"\n",
    "Ideas To Prevent Loss Nans\n",
    "1. Normalize Data Better\n",
    "2. Less Deep / Wide Architecture\n",
    "3. CNN instead of FCNN\n",
    "\"\"\"\n",
    "class AE(torch.nn.Module):\n",
    "    def __init__(self, numFrequencies, numRows, numFeatures=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder with Batch Normalization\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFrequencies * numRows, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFeatures),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Building a linear decoder with Batch Normalization\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFeatures, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFrequencies * numRows),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization to the weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eea307d1",
   "metadata": {
    "papermill": {
     "duration": 0.01608,
     "end_time": "2024-02-27T21:15:10.136930",
     "exception": false,
     "start_time": "2024-02-27T21:15:10.120850",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Autoencoder Feature Engineering - Spectrogram Level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0ec77090",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:15:10.169853Z",
     "iopub.status.busy": "2024-02-27T21:15:10.169270Z",
     "iopub.status.idle": "2024-02-27T21:15:21.744002Z",
     "shell.execute_reply": "2024-02-27T21:15:21.742751Z"
    },
    "papermill": {
     "duration": 11.594307,
     "end_time": "2024-02-27T21:15:21.746920",
     "exception": false,
     "start_time": "2024-02-27T21:15:10.152613",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 Âµs, sys: 2 Âµs, total: 3 Âµs\n",
      "Wall time: 8.82 Âµs\n",
      "Num Frequencies: 400\n",
      "Using:  cpu\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# ENGINEER FEATURES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "SPEC_FREQS = len(pd.read_parquet(f'{PATH}1000086677.parquet').columns[1:])\n",
    "print(f\"Num Frequencies: {SPEC_FREQS}\")\n",
    "numFeatures = 800\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu') # delete when issue resolved\n",
    "print(\"Using: \", device)\n",
    "\"\"\"\n",
    "Define 10min feature autoencoder\n",
    "\"\"\"\n",
    "model_10min = AE(SPEC_FREQS, 300, numFeatures=numFeatures)\n",
    "model_10min = model_10min.to(device)\n",
    "loss_function_10min = torch.nn.MSELoss()\n",
    "optimizer_10min = torch.optim.Adam(model_10min.parameters(),\n",
    "                            lr = 3e-4,\n",
    "                            )\n",
    "\n",
    "\"\"\"\n",
    "Define 20sec feature autoencoder\n",
    "\"\"\"\n",
    "model_20sec = AE(SPEC_FREQS, 10, numFeatures=numFeatures)\n",
    "model_20sec = model_20sec.to(device)\n",
    "loss_function_20sec = torch.nn.MSELoss()\n",
    "optimizer_20sec = torch.optim.Adam(model_20sec.parameters(),\n",
    "                            lr = 3e-4,\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3b53abe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-27T21:15:21.780112Z",
     "iopub.status.busy": "2024-02-27T21:15:21.779683Z",
     "iopub.status.idle": "2024-02-28T02:34:02.129923Z",
     "shell.execute_reply": "2024-02-28T02:34:02.123551Z"
    },
    "papermill": {
     "duration": 19120.39089,
     "end_time": "2024-02-28T02:34:02.153431",
     "exception": false,
     "start_time": "2024-02-27T21:15:21.762541",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Autoencoder on 17089 datapoints with batch size 100\n",
      "Batches 171: Done batch 0, 0.16649693250656128, 0.14608146250247955... Done batch 20, 1.4075658842921257, 0.9517939817160368... Done batch 40, 2.5865249410271645, 1.3062684210017323... Done batch 60, 3.714051477611065, 1.6441492019221187... Done batch 80, 4.300490640103817, 1.9638665663078427... Done batch 100, 4.79236651584506, 2.2806110745295882... Done batch 120, 5.232303109019995, 2.582220665179193... Done batch 140, 5.676802691072226, 2.849000684916973... Done batch 160, 6.072929002344608, 3.1064385743811727... Epoch 0 Summary: Avg Loss_10min: 0.03665933480257528, Avg Loss_20sec: 0.01888520389316026\n",
      "Batches 171: Done batch 0, 0.016862379387021065, 0.01036853902041912... Done batch 20, 0.4063644874840975, 0.24692776892334223... Done batch 40, 0.7872101478278637, 0.4714507516473532... Done batch 60, 1.1557267028838396, 0.6983602810651064... Done batch 80, 1.477969621308148, 0.919167285785079... Done batch 100, 1.7724137473851442, 1.1465184269472957... Done batch 120, 2.0008646408095956, 1.3742051683366299... Done batch 140, 2.2102434365078807, 1.6015245486050844... Done batch 160, 2.3985477723181248, 1.8249175604432821... Epoch 1 Summary: Avg Loss_10min: 0.014572103061217662, Avg Loss_20sec: 0.011324298077900159\n",
      "Batches 171: Done batch 0, 0.006663109175860882, 0.009451676160097122... Done batch 20, 0.1887863939628005, 0.22624980472028255... Done batch 40, 0.3659262643195689, 0.4320338098332286... Done batch 60, 0.5443478240631521, 0.6292288117110729... Done batch 80, 0.7168846088461578, 0.817890559323132... Done batch 100, 0.896771224681288, 1.0092808427289128... Done batch 120, 1.0743499523960054, 1.2004200126975775... Done batch 140, 1.2512929067015648, 1.3921176698058844... Done batch 160, 1.4200077303685248, 1.5810972936451435... Epoch 2 Summary: Avg Loss_10min: 0.0088022679569777, Avg Loss_20sec: 0.009802122785551854\n",
      "Batches 171: Done batch 0, 0.0061172968707978725, 0.008020940236747265... Done batch 20, 0.17210716288536787, 0.19031603494659066... Done batch 40, 0.3325514034368098, 0.37136811576783657... Done batch 60, 0.4936899500899017, 0.5580731118097901... Done batch 80, 0.651378380600363, 0.7389083933085203... Done batch 100, 0.8136430382728577, 0.9250551806762815... Done batch 120, 0.9744195365346968, 1.112203458789736... Done batch 140, 1.1312091941945255, 1.2970036412589252... Done batch 160, 1.2768132253549993, 1.475132770370692... Epoch 3 Summary: Avg Loss_10min: 0.00790796409584364, Avg Loss_20sec: 0.009144865316801776\n",
      "Batches 171: Done batch 0, 0.005601583514362574, 0.00772714801132679... Done batch 20, 0.15239085303619504, 0.18671909533441067... Done batch 40, 0.2960940939374268, 0.35665483633056283... Done batch 60, 0.4382316847331822, 0.5280656977556646... Done batch 80, 0.5758504411205649, 0.6895682998001575... Done batch 100, 0.7208341425284743, 0.8569190385751426... Done batch 120, 0.8673647628165781, 1.0232266867533326... Done batch 140, 1.0143068805336952, 1.1885758941061795... Done batch 160, 1.1553631615824997, 1.3508227313868701... Epoch 4 Summary: Avg Loss_10min: 0.00717728249783143, Avg Loss_20sec: 0.00837626353679606\n",
      "Batches 171: Done batch 0, 0.005462136585265398, 0.006580088287591934... Done batch 20, 0.14619356859475374, 0.1639862796291709... Done batch 40, 0.28457254776731133, 0.3221130669116974... Done batch 60, 0.42241486022248864, 0.48152928380295634... Done batch 80, 0.5552999558858573, 0.634991591796279... Done batch 100, 0.6944211260415614, 0.7946547926403582... Done batch 120, 0.8391336998902261, 0.953718273434788... Done batch 140, 0.9791481466963887, 1.1117041110992432... Done batch 160, 1.1113283950835466, 1.268286228645593... Epoch 5 Summary: Avg Loss_10min: 0.006895918859310492, Avg Loss_20sec: 0.00787834908366639\n",
      "Batches 171: Done batch 0, 0.0049343714490532875, 0.006457711104303598... Done batch 20, 0.13713852409273386, 0.15852765273302794... Done batch 40, 0.2689505014568567, 0.3121526166796684... Done batch 60, 0.39854512130841613, 0.468168823979795... Done batch 80, 0.5249492209404707, 0.6197130209766328... Done batch 100, 0.657821579836309, 0.7762328539974988... Done batch 120, 0.7940032975748181, 0.9315131329931319... Done batch 140, 0.9300101986154914, 1.0855049430392683... Done batch 160, 1.0591656980104744, 1.2384127033874393... Epoch 6 Summary: Avg Loss_10min: 0.006578555927007345, Avg Loss_20sec: 0.007690868035438117\n",
      "Batches 171: Done batch 0, 0.004764449317008257, 0.006105847656726837... Done batch 20, 0.13340534083545208, 0.15084882965311408... Done batch 40, 0.26278645964339375, 0.29649877082556486... Done batch 60, 0.38982086442410946, 0.44268350023776293... Done batch 80, 0.5133878863416612, 0.5827193818986416... Done batch 100, 0.6429908075369895, 0.7289801752194762... Done batch 120, 0.775434794370085, 0.8750229380093515... Done batch 140, 0.9084420213475823, 1.0208189631812274... Done batch 160, 1.0359732685610652, 1.1652023242786527... Epoch 7 Summary: Avg Loss_10min: 0.006437506431397813, Avg Loss_20sec: 0.007239511484356477\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "def extract_raw_values(spectrogram_id, r, offset, end):\n",
    "    return spectrograms[spectrogram_id][r+offset:r+end,:]\n",
    "\n",
    "# Create a SimpleImputer instance\n",
    "nan_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "batch_size = 100\n",
    "log_noise = 1\n",
    "print(f\"Training Autoencoder on {len(train)} datapoints with batch size {batch_size}\")\n",
    "num_epochs = 8 # fine with 2-3 epochs but should do more with GPU if possible\n",
    "for epoch in range(num_epochs): \n",
    "    num_batches = len(train) // batch_size + 1\n",
    "    epoch_loss_10min = 0.0\n",
    "    epoch_loss_20sec = 0.0\n",
    "    print(f\"Batches {num_batches}:\", end=' ')\n",
    "    \n",
    "    for i in range(num_batches):        \n",
    "        \n",
    "        row_start = i * batch_size\n",
    "        row_end = min((i + 1) * batch_size, len(train))\n",
    "        \n",
    "        input_10min_list = []\n",
    "        input_20sec_list = []\n",
    "        \n",
    "        for k in range(row_start, row_end):\n",
    "            row = train.iloc[k]\n",
    "            r = int((row['min'] + row['max']) // 4)\n",
    "\n",
    "            # get raw spectrogram values\n",
    "            raw_values_10min = extract_raw_values(row.spec_id, r, 0, 300)\n",
    "            raw_values_20sec = extract_raw_values(row.spec_id, r, 145, 155)\n",
    "\n",
    "            # Replace infinite values\n",
    "            raw_values_10min = np.where(np.isfinite(raw_values_10min), raw_values_10min, np.nan)\n",
    "            raw_values_20sec = np.where(np.isfinite(raw_values_20sec), raw_values_20sec, np.nan)            \n",
    "            \n",
    "            # Use SimpleImputer to handle NaN values\n",
    "            raw_values_10min = nan_imputer.fit_transform(raw_values_10min)\n",
    "            raw_values_20sec = nan_imputer.fit_transform(raw_values_20sec)\n",
    "            \n",
    "            # Convert to torch tensors and append to the lists\n",
    "            if len(raw_values_10min.flatten()) == 120000:\n",
    "                # normalize\n",
    "                raw_values_10min = np.log(raw_values_10min.flatten() + log_noise)\n",
    "                normalized_values_10min = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "                input_10min_list.append(normalized_values_10min)\n",
    "            if len(raw_values_20sec.flatten()) == 4000:\n",
    "                # normalize\n",
    "                raw_values_20sec = np.log(raw_values_20sec.flatten()  + log_noise)\n",
    "                normalized_values_20sec = (raw_values_20sec - raw_values_20sec.min()) / (raw_values_20sec.max() - raw_values_20sec.min())\n",
    "                input_20sec_list.append(normalized_values_20sec)\n",
    "        \n",
    "        # Forward pass through the autoencoders\n",
    "        input_10min_batch = torch.tensor(input_10min_list, dtype=torch.float32).to(device)\n",
    "        input_20sec_batch = torch.tensor(input_20sec_list, dtype=torch.float32).to(device)\n",
    "        \n",
    "        output_10min_batch = model_10min(input_10min_batch)\n",
    "        output_20sec_batch = model_20sec(input_20sec_batch)\n",
    "\n",
    "        # Calculate loss and perform optimization for 10min autoencoder\n",
    "        loss_10min = loss_function_10min(output_10min_batch, input_10min_batch)\n",
    "        optimizer_10min.zero_grad()\n",
    "        loss_10min.backward()\n",
    "        optimizer_10min.step()\n",
    "\n",
    "        # Calculate loss and perform optimization for 20sec autoencoder\n",
    "        loss_20sec = loss_function_20sec(output_20sec_batch, input_20sec_batch)\n",
    "        optimizer_20sec.zero_grad()\n",
    "        loss_20sec.backward()\n",
    "        optimizer_20sec.step()\n",
    "\n",
    "        # Accumulate epoch loss\n",
    "        epoch_loss_10min += loss_10min.item()\n",
    "        epoch_loss_20sec += loss_20sec.item()\n",
    "\n",
    "        # Clean up to avoid memory issues\n",
    "        del output_10min_batch, output_20sec_batch, input_10min_batch, input_10min_list, input_20sec_batch, input_20sec_list\n",
    "        \n",
    "        if i % 20 == 0:\n",
    "            print(f\"Done batch {i}, {epoch_loss_10min}, {epoch_loss_20sec}\", end = '... ')\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss_10min = epoch_loss_10min / num_batches\n",
    "    avg_loss_20sec = epoch_loss_20sec / num_batches\n",
    "\n",
    "    print(f\"Epoch {epoch} Summary: Avg Loss_10min: {avg_loss_10min}, Avg Loss_20sec: {avg_loss_20sec}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c1d9cc33",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T02:34:02.207682Z",
     "iopub.status.busy": "2024-02-28T02:34:02.206864Z",
     "iopub.status.idle": "2024-02-28T03:01:48.371929Z",
     "shell.execute_reply": "2024-02-28T03:01:48.370277Z"
    },
    "papermill": {
     "duration": 1666.197831,
     "end_time": "2024-02-28T03:01:48.374728",
     "exception": false,
     "start_time": "2024-02-28T02:34:02.176897",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating 1600 features on 17089 datapoints\n",
      "0 , 100 , 200 , 300 , 400 , 500 , 600 , 700 , 800 , 900 , 1000 , 1100 , 1200 , 1300 , 1400 , 1500 , 1600 , 1700 , 1800 , 1900 , 2000 , 2100 , 2200 , 2300 , 2400 , 2500 , 2600 , 2700 , 2800 , 2900 , 3000 , 3100 , 3200 , 3300 , 3400 , 3500 , 3600 , 3700 , 3800 , 3900 , 4000 , 4100 , 4200 , 4300 , 4400 , 4500 , 4600 , 4700 , 4800 , 4900 , 5000 , 5100 , 5200 , 5300 , 5400 , 5500 , 5600 , 5700 , 5800 , 5900 , 6000 , 6100 , 6200 , 6300 , 6400 , 6500 , 6600 , 6700 , 6800 , 6900 , 7000 , 7100 , 7200 , 7300 , 7400 , 7500 , 7600 , 7700 , 7800 , 7900 , 8000 , 8100 , 8200 , 8300 , 8400 , 8500 , 8600 , 8700 , 8800 , 8900 , 9000 , 9100 , 9200 , 9300 , 9400 , 9500 , 9600 , 9700 , 9800 , 9900 , 10000 , 10100 , 10200 , 10300 , 10400 , 10500 , 10600 , 10700 , 10800 , 10900 , 11000 , 11100 , 11200 , 11300 , 11400 , 11500 , 11600 , 11700 , 11800 , 11900 , 12000 , 12100 , 12200 , 12300 , 12400 , 12500 , 12600 , 12700 , 12800 , 12900 , 13000 , 13100 , 13200 , 13300 , 13400 , 13500 , 13600 , 13700 , 13800 , 13900 , 14000 , 14100 , 14200 , 14300 , 14400 , 14500 , 14600 , 14700 , 14800 , 14900 , 15000 , 15100 , 15200 , 15300 , 15400 , 15500 , 15600 , 15700 , 15800 , 15900 , 16000 , 16100 , 16200 , 16300 , 16400 , 16500 , 16600 , 16700 , 16800 , 16900 , 17000 , New train shape: (17089, 1612)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Get Feature Data\n",
    "\"\"\"\n",
    "print(f\"Generating {2 * numFeatures} features on {len(train)} datapoints\")\n",
    "FEATURES = [\"feature_{}_10min\".format(i) for i in range(numFeatures)]\n",
    "FEATURES += [\"feature_{}_20sec\".format(i) for i in range(numFeatures)]\n",
    "data = np.zeros((len(train), len(FEATURES)))\n",
    "\n",
    "for k in range(len(train)):\n",
    "    if k%100==0: print(k,', ',end='')\n",
    "    row = train.iloc[k]\n",
    "    r = int( (row['min'] + row['max'])//4 ) \n",
    "\n",
    "    # 10 MINUTE WINDOW FEATURES\n",
    "    # this will likey need to be unsqueezed or smth\n",
    "    raw_values_10min = np.log(spectrograms[row.spec_id][r:r+300, :].flatten() + log_noise)\n",
    "    normalized_values = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "    x = np.array(model_10min.encoder(torch.tensor([normalized_values]).to(device)).tolist())    \n",
    "    data[k,:numFeatures] = x\n",
    "\n",
    "    # 20 SECOND WINDOW FEATURES \n",
    "    # this will likey need to be unsqueezed or smth\n",
    "    raw_values_20sec = np.log(spectrograms[row.spec_id][r+145:r+155, :].flatten() + log_noise)\n",
    "    normalized_values = (raw_values_20sec - raw_values_20sec.min()) / (raw_values_20sec.max() - raw_values_20sec.min())\n",
    "    x = np.array(model_20sec.encoder(torch.tensor([normalized_values]).to(device)).tolist())\n",
    "    data[k,numFeatures:2*numFeatures] = x\n",
    "train[FEATURES] = data\n",
    "\n",
    "print('New train shape:',train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd79960f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:01:48.457967Z",
     "iopub.status.busy": "2024-02-28T03:01:48.457427Z",
     "iopub.status.idle": "2024-02-28T03:01:50.868084Z",
     "shell.execute_reply": "2024-02-28T03:01:50.866622Z"
    },
    "papermill": {
     "duration": 2.453963,
     "end_time": "2024-02-28T03:01:50.870703",
     "exception": false,
     "start_time": "2024-02-28T03:01:48.416740",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_790_20sec</th>\n",
       "      <th>feature_791_20sec</th>\n",
       "      <th>feature_792_20sec</th>\n",
       "      <th>feature_793_20sec</th>\n",
       "      <th>feature_794_20sec</th>\n",
       "      <th>feature_795_20sec</th>\n",
       "      <th>feature_796_20sec</th>\n",
       "      <th>feature_797_20sec</th>\n",
       "      <th>feature_798_20sec</th>\n",
       "      <th>feature_799_20sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>568657</td>\n",
       "      <td>789577333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>20654</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-1.218027</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.241587</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>0.337190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>582999</td>\n",
       "      <td>1552638400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>20230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-0.108367</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.230908</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>642382</td>\n",
       "      <td>14960202</td>\n",
       "      <td>1008.0</td>\n",
       "      <td>1032.0</td>\n",
       "      <td>5955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-0.592410</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.409068</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>751790</td>\n",
       "      <td>618728447</td>\n",
       "      <td>908.0</td>\n",
       "      <td>908.0</td>\n",
       "      <td>38549</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-1.218027</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.241587</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>778705</td>\n",
       "      <td>52296320</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>40955</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-1.218027</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.201671</td>\n",
       "      <td>1.750040</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17084</th>\n",
       "      <td>4293354003</td>\n",
       "      <td>1188113564</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16610</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>0.830302</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.892533</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17085</th>\n",
       "      <td>4293843368</td>\n",
       "      <td>1549502620</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15065</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-0.003880</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.630064</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>0.788677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17086</th>\n",
       "      <td>4294455489</td>\n",
       "      <td>2105480289</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>56</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17087</th>\n",
       "      <td>4294858825</td>\n",
       "      <td>657299228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.066667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>-0.045101</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.452943</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17088</th>\n",
       "      <td>4294958358</td>\n",
       "      <td>260520016</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>2508.0</td>\n",
       "      <td>25986</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>1.142938</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.376627</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17089 rows Ã— 1612 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           eeg_id     spec_id     min     max  patient_id  seizure_vote  \\\n",
       "0          568657   789577333     0.0    16.0       20654           0.0   \n",
       "1          582999  1552638400     0.0    38.0       20230           0.0   \n",
       "2          642382    14960202  1008.0  1032.0        5955           0.0   \n",
       "3          751790   618728447   908.0   908.0       38549           0.0   \n",
       "4          778705    52296320     0.0     0.0       40955           0.0   \n",
       "...           ...         ...     ...     ...         ...           ...   \n",
       "17084  4293354003  1188113564     0.0     0.0       16610           0.0   \n",
       "17085  4293843368  1549502620     0.0     0.0       15065           0.0   \n",
       "17086  4294455489  2105480289     0.0     0.0          56           0.0   \n",
       "17087  4294858825   657299228     0.0    12.0        4312           0.0   \n",
       "17088  4294958358   260520016  2508.0  2508.0       25986           0.0   \n",
       "\n",
       "       lpd_vote  gpd_vote  lrda_vote  grda_vote  ...  feature_790_20sec  \\\n",
       "0      0.000000      0.25   0.000000   0.166667  ...          -0.018423   \n",
       "1      0.857143      0.00   0.071429   0.000000  ...          -0.018423   \n",
       "2      0.000000      0.00   0.000000   0.000000  ...          -0.018423   \n",
       "3      0.000000      1.00   0.000000   0.000000  ...          -0.018423   \n",
       "4      0.000000      0.00   0.000000   0.000000  ...          -0.018423   \n",
       "...         ...       ...        ...        ...  ...                ...   \n",
       "17084  0.000000      0.00   0.000000   0.500000  ...          -0.018423   \n",
       "17085  0.000000      0.00   0.000000   0.500000  ...          -0.018423   \n",
       "17086  0.000000      0.00   0.000000   0.000000  ...                NaN   \n",
       "17087  0.000000      0.00   0.000000   0.066667  ...          -0.018423   \n",
       "17088  0.000000      0.00   0.000000   0.000000  ...          -0.018423   \n",
       "\n",
       "      feature_791_20sec  feature_792_20sec  feature_793_20sec  \\\n",
       "0             -1.218027          -0.042937                0.0   \n",
       "1             -0.108367          -0.042937                0.0   \n",
       "2             -0.592410          -0.042937                0.0   \n",
       "3             -1.218027          -0.042937                0.0   \n",
       "4             -1.218027          -0.042937                0.0   \n",
       "...                 ...                ...                ...   \n",
       "17084          0.830302          -0.042937                0.0   \n",
       "17085         -0.003880          -0.042937                0.0   \n",
       "17086               NaN                NaN                NaN   \n",
       "17087         -0.045101          -0.042937                0.0   \n",
       "17088          1.142938          -0.042937                0.0   \n",
       "\n",
       "       feature_794_20sec  feature_795_20sec  feature_796_20sec  \\\n",
       "0                    0.0                0.0          -1.241587   \n",
       "1                    0.0                0.0           0.230908   \n",
       "2                    0.0                0.0           0.409068   \n",
       "3                    0.0                0.0          -1.241587   \n",
       "4                    0.0                0.0          -1.201671   \n",
       "...                  ...                ...                ...   \n",
       "17084                0.0                0.0           0.892533   \n",
       "17085                0.0                0.0          -0.630064   \n",
       "17086                NaN                NaN                NaN   \n",
       "17087                0.0                0.0           0.452943   \n",
       "17088                0.0                0.0           2.376627   \n",
       "\n",
       "       feature_797_20sec  feature_798_20sec  feature_799_20sec  \n",
       "0              -0.111487          -0.143369           0.337190  \n",
       "1              -0.111487          -0.143369          -0.312104  \n",
       "2              -0.111487          -0.143369          -0.312104  \n",
       "3              -0.111487          -0.143369          -0.312104  \n",
       "4               1.750040          -0.143369          -0.312104  \n",
       "...                  ...                ...                ...  \n",
       "17084          -0.111487          -0.143369          -0.312104  \n",
       "17085          -0.111487          -0.143369           0.788677  \n",
       "17086                NaN                NaN                NaN  \n",
       "17087          -0.111487          -0.143369          -0.312104  \n",
       "17088          -0.111487          -0.143369          -0.312104  \n",
       "\n",
       "[17089 rows x 1612 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Columns to be excluded from scaling\n",
    "excluded_columns = ['eeg_id', 'spec_id', 'min', 'max', 'patient_id', 'seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote','target']\n",
    "\n",
    "# Save the columns to be excluded\n",
    "excluded_data = train[excluded_columns]\n",
    "\n",
    "# DataFrame with only the columns to be scaled\n",
    "features = train.drop(columns=excluded_columns)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform them\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Create a DataFrame from the scaled features\n",
    "features_scaled_df = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "\n",
    "# Concatenate the scaled features with the excluded columns\n",
    "train_scaled_df = pd.concat([excluded_data.reset_index(drop=True),features_scaled_df,], axis=1)\n",
    "# train_scaled_df.to_csv(\"/kaggle/working/\")\n",
    "train_scaled_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58ccda7d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:01:50.952727Z",
     "iopub.status.busy": "2024-02-28T03:01:50.952298Z",
     "iopub.status.idle": "2024-02-28T03:01:57.159123Z",
     "shell.execute_reply": "2024-02-28T03:01:57.157686Z"
    },
    "papermill": {
     "duration": 6.251269,
     "end_time": "2024-02-28T03:01:57.162084",
     "exception": false,
     "start_time": "2024-02-28T03:01:50.910815",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spec_id</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_790_20sec</th>\n",
       "      <th>feature_791_20sec</th>\n",
       "      <th>feature_792_20sec</th>\n",
       "      <th>feature_793_20sec</th>\n",
       "      <th>feature_794_20sec</th>\n",
       "      <th>feature_795_20sec</th>\n",
       "      <th>feature_796_20sec</th>\n",
       "      <th>feature_797_20sec</th>\n",
       "      <th>feature_798_20sec</th>\n",
       "      <th>feature_799_20sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>1.708900e+04</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>17089.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>17003.0</td>\n",
       "      <td>17003.0</td>\n",
       "      <td>17003.0</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>1.700300e+04</td>\n",
       "      <td>17003.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.135226e+09</td>\n",
       "      <td>1.080640e+09</td>\n",
       "      <td>401.650711</td>\n",
       "      <td>431.761191</td>\n",
       "      <td>32839.981977</td>\n",
       "      <td>0.152810</td>\n",
       "      <td>0.142456</td>\n",
       "      <td>0.104062</td>\n",
       "      <td>0.065407</td>\n",
       "      <td>0.114851</td>\n",
       "      <td>...</td>\n",
       "      <td>8.566798e-18</td>\n",
       "      <td>-1.065626e-16</td>\n",
       "      <td>-8.253378e-18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-5.505735e-17</td>\n",
       "      <td>-3.844612e-17</td>\n",
       "      <td>-2.653618e-17</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.235712e+09</td>\n",
       "      <td>6.251739e+08</td>\n",
       "      <td>1226.839779</td>\n",
       "      <td>1232.863269</td>\n",
       "      <td>18351.751174</td>\n",
       "      <td>0.331563</td>\n",
       "      <td>0.295541</td>\n",
       "      <td>0.258825</td>\n",
       "      <td>0.187005</td>\n",
       "      <td>0.271425</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029e+00</td>\n",
       "      <td>1.000029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>5.686570e+05</td>\n",
       "      <td>3.537330e+05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.842285e-02</td>\n",
       "      <td>-1.218027e+00</td>\n",
       "      <td>-4.293726e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.241587e+00</td>\n",
       "      <td>-1.114867e-01</td>\n",
       "      <td>-1.433692e-01</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.062096e+09</td>\n",
       "      <td>5.396648e+08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>17408.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.842285e-02</td>\n",
       "      <td>-7.881088e-01</td>\n",
       "      <td>-4.293726e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-8.647463e-01</td>\n",
       "      <td>-1.114867e-01</td>\n",
       "      <td>-1.433692e-01</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2.123560e+09</td>\n",
       "      <td>1.073264e+09</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>32068.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.842285e-02</td>\n",
       "      <td>-1.432888e-01</td>\n",
       "      <td>-4.293726e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.022258e-01</td>\n",
       "      <td>-1.114867e-01</td>\n",
       "      <td>-1.433692e-01</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>3.208261e+09</td>\n",
       "      <td>1.641428e+09</td>\n",
       "      <td>308.000000</td>\n",
       "      <td>346.000000</td>\n",
       "      <td>48272.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.068966</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.842285e-02</td>\n",
       "      <td>5.967700e-01</td>\n",
       "      <td>-4.293726e-02</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.692814e-01</td>\n",
       "      <td>-1.114867e-01</td>\n",
       "      <td>-1.433692e-01</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>4.294958e+09</td>\n",
       "      <td>2.147388e+09</td>\n",
       "      <td>17556.000000</td>\n",
       "      <td>17632.000000</td>\n",
       "      <td>65494.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.162860e+01</td>\n",
       "      <td>6.062694e+00</td>\n",
       "      <td>4.660862e+01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.112061e+00</td>\n",
       "      <td>2.826509e+01</td>\n",
       "      <td>2.082453e+01</td>\n",
       "      <td>9.926018</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows Ã— 1611 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             eeg_id       spec_id           min           max    patient_id  \\\n",
       "count  1.708900e+04  1.708900e+04  17089.000000  17089.000000  17089.000000   \n",
       "mean   2.135226e+09  1.080640e+09    401.650711    431.761191  32839.981977   \n",
       "std    1.235712e+09  6.251739e+08   1226.839779   1232.863269  18351.751174   \n",
       "min    5.686570e+05  3.537330e+05      0.000000      0.000000     56.000000   \n",
       "25%    1.062096e+09  5.396648e+08      0.000000      4.000000  17408.000000   \n",
       "50%    2.123560e+09  1.073264e+09      0.000000     40.000000  32068.000000   \n",
       "75%    3.208261e+09  1.641428e+09    308.000000    346.000000  48272.000000   \n",
       "max    4.294958e+09  2.147388e+09  17556.000000  17632.000000  65494.000000   \n",
       "\n",
       "       seizure_vote      lpd_vote      gpd_vote     lrda_vote     grda_vote  \\\n",
       "count  17089.000000  17089.000000  17089.000000  17089.000000  17089.000000   \n",
       "mean       0.152810      0.142456      0.104062      0.065407      0.114851   \n",
       "std        0.331563      0.295541      0.258825      0.187005      0.271425   \n",
       "min        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "25%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.000000      0.000000      0.000000   \n",
       "75%        0.000000      0.068966      0.000000      0.000000      0.000000   \n",
       "max        1.000000      1.000000      1.000000      1.000000      1.000000   \n",
       "\n",
       "       ...  feature_790_20sec  feature_791_20sec  feature_792_20sec  \\\n",
       "count  ...       1.700300e+04       1.700300e+04       1.700300e+04   \n",
       "mean   ...       8.566798e-18      -1.065626e-16      -8.253378e-18   \n",
       "std    ...       1.000029e+00       1.000029e+00       1.000029e+00   \n",
       "min    ...      -1.842285e-02      -1.218027e+00      -4.293726e-02   \n",
       "25%    ...      -1.842285e-02      -7.881088e-01      -4.293726e-02   \n",
       "50%    ...      -1.842285e-02      -1.432888e-01      -4.293726e-02   \n",
       "75%    ...      -1.842285e-02       5.967700e-01      -4.293726e-02   \n",
       "max    ...       8.162860e+01       6.062694e+00       4.660862e+01   \n",
       "\n",
       "       feature_793_20sec  feature_794_20sec  feature_795_20sec  \\\n",
       "count            17003.0            17003.0            17003.0   \n",
       "mean                 0.0                0.0                0.0   \n",
       "std                  0.0                0.0                0.0   \n",
       "min                  0.0                0.0                0.0   \n",
       "25%                  0.0                0.0                0.0   \n",
       "50%                  0.0                0.0                0.0   \n",
       "75%                  0.0                0.0                0.0   \n",
       "max                  0.0                0.0                0.0   \n",
       "\n",
       "       feature_796_20sec  feature_797_20sec  feature_798_20sec  \\\n",
       "count       1.700300e+04       1.700300e+04       1.700300e+04   \n",
       "mean       -5.505735e-17      -3.844612e-17      -2.653618e-17   \n",
       "std         1.000029e+00       1.000029e+00       1.000029e+00   \n",
       "min        -1.241587e+00      -1.114867e-01      -1.433692e-01   \n",
       "25%        -8.647463e-01      -1.114867e-01      -1.433692e-01   \n",
       "50%        -1.022258e-01      -1.114867e-01      -1.433692e-01   \n",
       "75%         6.692814e-01      -1.114867e-01      -1.433692e-01   \n",
       "max         5.112061e+00       2.826509e+01       2.082453e+01   \n",
       "\n",
       "       feature_799_20sec  \n",
       "count       17003.000000  \n",
       "mean            0.000000  \n",
       "std             1.000029  \n",
       "min            -0.312104  \n",
       "25%            -0.312104  \n",
       "50%            -0.312104  \n",
       "75%            -0.312104  \n",
       "max             9.926018  \n",
       "\n",
       "[8 rows x 1611 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scaled_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059d3656",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T15:48:13.200329Z",
     "iopub.status.busy": "2024-01-14T15:48:13.199779Z",
     "iopub.status.idle": "2024-01-14T15:48:13.206828Z",
     "shell.execute_reply": "2024-01-14T15:48:13.205408Z",
     "shell.execute_reply.started": "2024-01-14T15:48:13.200282Z"
    },
    "papermill": {
     "duration": 0.040758,
     "end_time": "2024-02-28T03:01:57.244392",
     "exception": false,
     "start_time": "2024-02-28T03:01:57.203634",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>8 |</span></b> <b>TRAIN MODEL</b></div>\n",
    "\n",
    "* Original work uses catboost, let's try with XGBoost in this version to see the difference in model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bab0e60c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:01:57.326480Z",
     "iopub.status.busy": "2024-02-28T03:01:57.326001Z",
     "iopub.status.idle": "2024-02-28T03:01:57.561977Z",
     "shell.execute_reply": "2024-02-28T03:01:57.560736Z"
    },
    "papermill": {
     "duration": 0.281221,
     "end_time": "2024-02-28T03:01:57.565411",
     "exception": false,
     "start_time": "2024-02-28T03:01:57.284190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "from sklearn.svm import SVC\n",
    "import gc\n",
    "from sklearn.model_selection import KFold, GroupKFold\n",
    "import pickle\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from scipy.special import rel_entr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c95f4cd5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:01:57.649194Z",
     "iopub.status.busy": "2024-02-28T03:01:57.648472Z",
     "iopub.status.idle": "2024-02-28T03:01:57.654834Z",
     "shell.execute_reply": "2024-02-28T03:01:57.653446Z"
    },
    "papermill": {
     "duration": 0.051061,
     "end_time": "2024-02-28T03:01:57.657480",
     "exception": false,
     "start_time": "2024-02-28T03:01:57.606419",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1600"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(FEATURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fc2ff10f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:01:57.740443Z",
     "iopub.status.busy": "2024-02-28T03:01:57.738963Z",
     "iopub.status.idle": "2024-02-28T03:11:57.443565Z",
     "shell.execute_reply": "2024-02-28T03:11:57.442166Z"
    },
    "papermill": {
     "duration": 599.790126,
     "end_time": "2024-02-28T03:11:57.487781",
     "exception": false,
     "start_time": "2024-02-28T03:01:57.697655",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#########################\n",
      "### Fold 1\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "Kale Divergence: 1.0205473546464672\n",
      "#########################\n",
      "### Fold 2\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "Kale Divergence: 1.2669746666311315\n",
      "#########################\n",
      "### Fold 3\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "Kale Divergence: 1.1330065057377365\n",
      "#########################\n",
      "### Fold 4\n",
      "### train size 13671, valid size 3418\n",
      "#########################\n",
      "Kale Divergence: 1.0422925316761045\n",
      "#########################\n",
      "### Fold 5\n",
      "### train size 13672, valid size 3417\n",
      "#########################\n",
      "Kale Divergence: 1.111646223019359\n"
     ]
    }
   ],
   "source": [
    "all_oof = []\n",
    "all_true = []\n",
    "TARS = {'Seizure':0, 'LPD':1, 'GPD':2, 'LRDA':3, 'GRDA':4, 'Other':5}\n",
    "n_splits = 5\n",
    "gkf = GroupKFold(n_splits=5)\n",
    "for i, (train_index, valid_index) in enumerate(gkf.split(train_scaled_df, train_scaled_df.target, train_scaled_df.patient_id)):   \n",
    "    if i >= n_splits:\n",
    "        continue\n",
    "    print('#'*25)\n",
    "    print(f'### Fold {i+1}')\n",
    "    print(f'### train size {len(train_index)}, valid size {len(valid_index)}')\n",
    "    print('#'*25)\n",
    "    \n",
    "    # Instantiate the XGBRegressor model\n",
    "    xgb_model = xgb.XGBRegressor(objective='reg:squarederror', learning_rate = 0.1) # uses MSE to predict probabilities\n",
    "\n",
    "    model = MultiOutputRegressor(xgb_model) # since we have multiple outputs\n",
    "    \n",
    "#     model = SVC(probability=True)    \n",
    "    LABEL_NAMES = ['seizure_vote', 'lpd_vote', 'gpd_vote', 'lrda_vote', 'grda_vote', 'other_vote']\n",
    "    # Prepare training and validation data\n",
    "    X_train = train_scaled_df.loc[train_index, FEATURES]\n",
    "    y_train = train_scaled_df.loc[train_index, LABEL_NAMES]\n",
    "    X_valid = train_scaled_df.loc[valid_index, FEATURES]\n",
    "    y_valid = train_scaled_df.loc[valid_index, LABEL_NAMES]\n",
    "    model.fit(X_train, y_train, verbose=True,) \n",
    "\n",
    "    with open(f'XGBoost_f{i}.pkl', 'wb') as f:\n",
    "        pickle.dump(model, f)\n",
    "\n",
    "    y_pred = model.predict(X_valid)\n",
    "    y_pred[y_pred < 0] = 0\n",
    "    oof = y_pred / np.sum(y_pred, axis=1).reshape(-1,1) # ensure they sum to 1\n",
    "    true = y_valid.values\n",
    "    kl_divergence = np.mean(np.sum(true * (np.log(true + 1e-10) - np.log(oof + 1e-10)), axis=1))\n",
    "    print(f\"Kale Divergence: {kl_divergence}\")\n",
    "    \n",
    "    all_oof.append(oof)\n",
    "    all_true.append(true)\n",
    "    \n",
    "    del X_train, y_train, X_valid, y_valid, oof\n",
    "    gc.collect()\n",
    "    \n",
    "all_oof = np.concatenate(all_oof)\n",
    "all_true = np.concatenate(all_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f09b6363",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-14T16:08:35.106804Z",
     "iopub.status.busy": "2024-01-14T16:08:35.106237Z",
     "iopub.status.idle": "2024-01-14T16:08:35.112735Z",
     "shell.execute_reply": "2024-01-14T16:08:35.111659Z",
     "shell.execute_reply.started": "2024-01-14T16:08:35.106757Z"
    },
    "papermill": {
     "duration": 0.040763,
     "end_time": "2024-02-28T03:11:57.569870",
     "exception": false,
     "start_time": "2024-02-28T03:11:57.529107",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>10 |</span></b> <b>FEATURE IMPORTANCE</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "82de93a1",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:11:57.656273Z",
     "iopub.status.busy": "2024-02-28T03:11:57.655823Z",
     "iopub.status.idle": "2024-02-28T03:11:57.674829Z",
     "shell.execute_reply": "2024-02-28T03:11:57.674062Z"
    },
    "papermill": {
     "duration": 0.064784,
     "end_time": "2024-02-28T03:11:57.677262",
     "exception": false,
     "start_time": "2024-02-28T03:11:57.612478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test shape (1, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>patient_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>853520</td>\n",
       "      <td>3911565283</td>\n",
       "      <td>6885</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   spectrogram_id      eeg_id  patient_id\n",
       "0          853520  3911565283        6885"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv('/kaggle/input/hms-harmful-brain-activity-classification/test.csv')\n",
    "print('Test shape',test.shape)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6194ead5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:11:57.761838Z",
     "iopub.status.busy": "2024-02-28T03:11:57.761067Z",
     "iopub.status.idle": "2024-02-28T03:11:57.845008Z",
     "shell.execute_reply": "2024-02-28T03:11:57.844077Z"
    },
    "papermill": {
     "duration": 0.128773,
     "end_time": "2024-02-28T03:11:57.847246",
     "exception": false,
     "start_time": "2024-02-28T03:11:57.718473",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 1 spectrogram parquets\n",
      "0 , CPU times: user 74.2 ms, sys: 3.32 ms, total: 77.5 ms\n",
      "Wall time: 75.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# READ ALL TEST SPECTROGRAMS\n",
    "PATH2 = '/kaggle/input/hms-harmful-brain-activity-classification/test_spectrograms/'\n",
    "files = os.listdir(PATH2)\n",
    "print(f'There are {len(files)} spectrogram parquets')\n",
    "\n",
    "spectrograms_test = {}\n",
    "for i,f in enumerate(files):\n",
    "    if i%100==0: print(i,', ',end='')\n",
    "    tmp = pd.read_parquet(f'{PATH2}{f}')\n",
    "    name = int(f.split('.')[0])\n",
    "    spectrograms_test[name] = tmp.iloc[:,1:].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "277c6cea",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:11:57.932235Z",
     "iopub.status.busy": "2024-02-28T03:11:57.931321Z",
     "iopub.status.idle": "2024-02-28T03:11:58.906366Z",
     "shell.execute_reply": "2024-02-28T03:11:58.905088Z"
    },
    "papermill": {
     "duration": 1.020606,
     "end_time": "2024-02-28T03:11:58.909109",
     "exception": false,
     "start_time": "2024-02-28T03:11:57.888503",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 Âµs, sys: 1 Âµs, total: 4 Âµs\n",
      "Wall time: 8.82 Âµs\n",
      "We are creating 1600 features for 1 rows... 0 , 1600 (1, 1600)\n",
      "\n",
      "New test shape: (1, 1603)\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# ENGINEER FEATURES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "SPEC_COLS = pd.read_parquet(f'{PATH}1000086677.parquet').columns[1:]\n",
    "\n",
    "TEST_FEATURES = FEATURES\n",
    "\n",
    "print(f'We are creating {len(TEST_FEATURES)} features for {len(test)} rows... ',end='')\n",
    "\n",
    "\n",
    "# A data matrix data is initialized to store the new features for each eeg_id in the train DataFrame.\n",
    "# For each row in train, the code calculates the mean and minimum values within the specified 10-minute and 20-second windows.\n",
    "# These calculated values are then stored in the data matrix.\n",
    "# Finally, the matrix is added to the train DataFrame as new columns.\n",
    "\n",
    "data = np.zeros((len(test),len(TEST_FEATURES)))\n",
    "for k in range(len(test)):\n",
    "    if k%100==0: print(k,', ',end='')\n",
    "    row = test.iloc[k]       \n",
    "    s = int( row.spectrogram_id )\n",
    "    spec = pd.read_parquet(f'{PATH2}{s}.parquet')\n",
    "    raw_values_10min = np.log(spec.iloc[:,1:].values.flatten() + log_noise)\n",
    "    normalized_values = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "    x = np.array(model_10min.encoder(torch.tensor([normalized_values]).to(device)).tolist())   \n",
    "    data[k,:numFeatures] = x\n",
    "\n",
    "    # 20 SECOND WINDOW FEATURES \n",
    "    # this will likey need to be unsqueezed or smth\n",
    "    raw_values_20sec = np.log(spec.iloc[145:155,1:].values.flatten() + log_noise)\n",
    "    normalized_values = (raw_values_20sec - raw_values_20sec.min()) / (raw_values_20sec.max() - raw_values_20sec.min())\n",
    "    x = np.array(model_20sec.encoder(torch.tensor([normalized_values]).to(device)).tolist())  \n",
    "    data[k,numFeatures:2*numFeatures] = x    \n",
    "\n",
    "print(len(TEST_FEATURES), data.shape)\n",
    "test[TEST_FEATURES] = data\n",
    "\n",
    "    \n",
    "print()\n",
    "print('New test shape:',test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c826dbfe",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:11:58.994780Z",
     "iopub.status.busy": "2024-02-28T03:11:58.993625Z",
     "iopub.status.idle": "2024-02-28T03:11:59.164393Z",
     "shell.execute_reply": "2024-02-28T03:11:59.163410Z"
    },
    "papermill": {
     "duration": 0.216361,
     "end_time": "2024-02-28T03:11:59.166924",
     "exception": false,
     "start_time": "2024-02-28T03:11:58.950563",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>spectrogram_id</th>\n",
       "      <th>patient_id</th>\n",
       "      <th>feature_0_10min</th>\n",
       "      <th>feature_1_10min</th>\n",
       "      <th>feature_2_10min</th>\n",
       "      <th>feature_3_10min</th>\n",
       "      <th>feature_4_10min</th>\n",
       "      <th>feature_5_10min</th>\n",
       "      <th>feature_6_10min</th>\n",
       "      <th>...</th>\n",
       "      <th>feature_790_20sec</th>\n",
       "      <th>feature_791_20sec</th>\n",
       "      <th>feature_792_20sec</th>\n",
       "      <th>feature_793_20sec</th>\n",
       "      <th>feature_794_20sec</th>\n",
       "      <th>feature_795_20sec</th>\n",
       "      <th>feature_796_20sec</th>\n",
       "      <th>feature_797_20sec</th>\n",
       "      <th>feature_798_20sec</th>\n",
       "      <th>feature_799_20sec</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>853520</td>\n",
       "      <td>6885</td>\n",
       "      <td>-0.199303</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.00793</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018423</td>\n",
       "      <td>0.92318</td>\n",
       "      <td>-0.042937</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.012949</td>\n",
       "      <td>-0.111487</td>\n",
       "      <td>-0.143369</td>\n",
       "      <td>-0.312104</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 1603 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  spectrogram_id  patient_id  feature_0_10min  feature_1_10min  \\\n",
       "0  3911565283          853520        6885        -0.199303              0.0   \n",
       "\n",
       "   feature_2_10min  feature_3_10min  feature_4_10min  feature_5_10min  \\\n",
       "0         -0.00793              0.0              0.0         -0.00793   \n",
       "\n",
       "   feature_6_10min  ...  feature_790_20sec  feature_791_20sec  \\\n",
       "0              0.0  ...          -0.018423            0.92318   \n",
       "\n",
       "   feature_792_20sec  feature_793_20sec  feature_794_20sec  feature_795_20sec  \\\n",
       "0          -0.042937                0.0                0.0                0.0   \n",
       "\n",
       "   feature_796_20sec  feature_797_20sec  feature_798_20sec  feature_799_20sec  \n",
       "0          -0.012949          -0.111487          -0.143369          -0.312104  \n",
       "\n",
       "[1 rows x 1603 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Columns to be excluded from scaling\n",
    "excluded_columns = ['eeg_id', 'spectrogram_id', 'patient_id']\n",
    "\n",
    "# Save the columns to be excluded\n",
    "excluded_data = test[excluded_columns]\n",
    "\n",
    "# DataFrame with only the columns to be scaled\n",
    "features = test.drop(columns=excluded_columns)\n",
    "\n",
    "# Initialize the StandardScaler\n",
    "# scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler to the features and transform them\n",
    "features_scaled = scaler.transform(features)\n",
    "\n",
    "# Create a DataFrame from the scaled features\n",
    "features_scaled_df = pd.DataFrame(features_scaled, columns=features.columns)\n",
    "\n",
    "# Concatenate the scaled features with the excluded columns\n",
    "test_scaled_df = pd.concat([excluded_data.reset_index(drop=True),features_scaled_df,], axis=1)\n",
    "test_scaled_df \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4777db76",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:11:59.256633Z",
     "iopub.status.busy": "2024-02-28T03:11:59.256197Z",
     "iopub.status.idle": "2024-02-28T03:12:07.358503Z",
     "shell.execute_reply": "2024-02-28T03:12:07.357186Z"
    },
    "papermill": {
     "duration": 8.150174,
     "end_time": "2024-02-28T03:12:07.361413",
     "exception": false,
     "start_time": "2024-02-28T03:11:59.211239",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 , 1 , 2 , 3 , 4 , Test preds shape (1, 6)\n"
     ]
    }
   ],
   "source": [
    "# INFER XGBOOST ON TEST\n",
    "preds = []\n",
    "\n",
    "for i in range(n_splits):\n",
    "    print(i, ', ', end='')\n",
    "    \n",
    "    # Load the XGBoost model\n",
    "    with open(f'XGBoost_f{i}.pkl', 'rb') as f:\n",
    "        model = pickle.load(f)\n",
    "    \n",
    "    # Make predictions\n",
    "    test_data_scaled = test_scaled_df[TEST_FEATURES]\n",
    "    \n",
    "    # data_imputed = imputer.fit_transform(test_data_scaled)\n",
    "    \n",
    "    pred = model.predict(test_data_scaled)\n",
    "    pred[pred < 0] = 0\n",
    "    pred = pred / np.sum(pred, axis=1).reshape(-1,1)\n",
    "    preds.append(pred) \n",
    "\n",
    "# Average the predictions from each fold\n",
    "pred = np.mean(preds, axis=0)\n",
    "print('Test preds shape', pred.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8c65d5",
   "metadata": {
    "papermill": {
     "duration": 0.042283,
     "end_time": "2024-02-28T03:12:07.447599",
     "exception": false,
     "start_time": "2024-02-28T03:12:07.405316",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# <div style=\"padding: 30px;color:white;margin:10;font-size:60%;text-align:left;display:fill;border-radius:10px;background-color:#FFFFFF;overflow:hidden;background-color:#FFCE30\"><b><span style='color:#FFFFFF'>12 |</span></b> <b>SUBMISSION</b></div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fa2fb640",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:12:07.536803Z",
     "iopub.status.busy": "2024-02-28T03:12:07.536380Z",
     "iopub.status.idle": "2024-02-28T03:12:07.562224Z",
     "shell.execute_reply": "2024-02-28T03:12:07.560946Z"
    },
    "papermill": {
     "duration": 0.073291,
     "end_time": "2024-02-28T03:12:07.564864",
     "exception": false,
     "start_time": "2024-02-28T03:12:07.491573",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission shape (1, 7)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eeg_id</th>\n",
       "      <th>seizure_vote</th>\n",
       "      <th>lpd_vote</th>\n",
       "      <th>gpd_vote</th>\n",
       "      <th>lrda_vote</th>\n",
       "      <th>grda_vote</th>\n",
       "      <th>other_vote</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3911565283</td>\n",
       "      <td>0.042841</td>\n",
       "      <td>0.04975</td>\n",
       "      <td>0.003679</td>\n",
       "      <td>0.045709</td>\n",
       "      <td>0.068547</td>\n",
       "      <td>0.789472</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       eeg_id  seizure_vote  lpd_vote  gpd_vote  lrda_vote  grda_vote  \\\n",
       "0  3911565283      0.042841   0.04975  0.003679   0.045709   0.068547   \n",
       "\n",
       "   other_vote  \n",
       "0    0.789472  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sub = pd.DataFrame({'eeg_id':test.eeg_id.values})\n",
    "sub[LABEL_NAMES] = pred\n",
    "sub.to_csv('submission.csv',index=False)\n",
    "print('Submission shape',sub.shape)\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "223ab0c4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-02-28T03:12:07.653588Z",
     "iopub.status.busy": "2024-02-28T03:12:07.653171Z",
     "iopub.status.idle": "2024-02-28T03:12:07.665399Z",
     "shell.execute_reply": "2024-02-28T03:12:07.664213Z"
    },
    "papermill": {
     "duration": 0.059272,
     "end_time": "2024-02-28T03:12:07.667749",
     "exception": false,
     "start_time": "2024-02-28T03:12:07.608477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    1.0\n",
       "dtype: float32"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# SANITY CHECK TO CONFIRM PREDICTIONS SUM TO ONE\n",
    "sub.iloc[:,-6:].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6179b01",
   "metadata": {
    "papermill": {
     "duration": 0.042717,
     "end_time": "2024-02-28T03:12:07.753586",
     "exception": false,
     "start_time": "2024-02-28T03:12:07.710869",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    },
    {
     "datasetId": 4297782,
     "sourceId": 7392775,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4334995,
     "sourceId": 7447509,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30635,
   "isGpuEnabled": false,
   "isInternetEnabled": false,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 21497.734509,
   "end_time": "2024-02-28T03:12:11.126212",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-02-27T21:13:53.391703",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
