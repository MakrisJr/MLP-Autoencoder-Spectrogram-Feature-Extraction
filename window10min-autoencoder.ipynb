{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "480dcb96",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-03-13T17:01:56.753357Z",
     "iopub.status.busy": "2024-03-13T17:01:56.752717Z",
     "iopub.status.idle": "2024-03-13T17:01:57.637458Z",
     "shell.execute_reply": "2024-03-13T17:01:57.636400Z"
    },
    "papermill": {
     "duration": 0.894493,
     "end_time": "2024-03-13T17:01:57.640470",
     "exception": false,
     "start_time": "2024-03-13T17:01:56.745977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd, numpy as np\n",
    "from glob import glob\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "VER = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8946cc4b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:01:57.651658Z",
     "iopub.status.busy": "2024-03-13T17:01:57.650952Z",
     "iopub.status.idle": "2024-03-13T17:02:06.512531Z",
     "shell.execute_reply": "2024-03-13T17:02:06.511084Z"
    },
    "papermill": {
     "duration": 8.870564,
     "end_time": "2024-03-13T17:02:06.515506",
     "exception": false,
     "start_time": "2024-03-13T17:01:57.644942",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pyarrow.parquet as pq\n",
    "from torch.utils.data import Dataset\n",
    "import torch\n",
    "from sklearn.impute import SimpleImputer\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "\"\"\"\n",
    "# CAN RUN THIS FROM ANY NOTEBOOK\n",
    " \n",
    "from spectrogram_preprocessor import *\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "\n",
    "spectrogram_dataset = SpectrogramDataset(\"train\", transform=transforms.Compose([\n",
    "    MiddleCrop(), Impute(), LogTransform(), StackFrequencyBands()])\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(spectrogram_dataset, batch_size=32,\n",
    "                        shuffle=True, num_workers=0)\n",
    "\n",
    "\n",
    "for i_batch, sample_batched in enumerate(dataloader):\n",
    "    print(i_batch, sample_batched[\"values\"].shape) #, \"labels: \", sample_batched[1].shape)\n",
    "    print(sample_batched[\"seizure_vote\"].shape)\n",
    "    print(sample_batched[\"lpd_vote\"].shape)\n",
    "    print(sample_batched[\"gpd_vote\"].shape)\n",
    "    print(sample_batched[\"lrda_vote\"].shape)\n",
    "    print(sample_batched[\"grda_vote\"].shape)\n",
    "    print(len(sample_batched[\"target\"])) # for some reason target is a list\n",
    "    # observe 4th batch and stop.\n",
    "    if i_batch == 3:\n",
    "        break\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "class SpectrogramDataset(Dataset):\n",
    "    \"\"\"EEG spectrograms dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, data_type, csv_file=\"/kaggle/input/hms-harmful-brain-activity-classification/train.csv\", root_dir=\"/kaggle/input/hms-harmful-brain-activity-classification\", transform=None):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_type = data_type\n",
    "        if data_type == \"train\":\n",
    "            self.data_path = root_dir + \"/train_spectrograms\"\n",
    "            self.df_train = process_training_csv(csv_file)\n",
    "        elif data_type == \"test\":\n",
    "            self.data_path = root_dir + \"/test_spectrograms\"\n",
    "            self.df_train = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def reset(self):\n",
    "        self.df_train = process_training_csv(\"hms-harmful-brain-activity-classification/train.csv\")\n",
    "        \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df_train)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "\n",
    "        if (self.data_type == \"train\"):\n",
    "            parquet_path = os.path.join(self.data_path, str(self.df_train.iloc[idx]['spec_id']) + \".parquet\")\n",
    "            parquet_table = pq.read_table(parquet_path)\n",
    "\n",
    "            sample = {\"values\" : parquet_table.to_pandas().values[:, 1:], # drop the time column\n",
    "                \"min\" : self.df_train.iloc[idx]['min'],\n",
    "                \"max\" : self.df_train.iloc[idx]['max']\n",
    "                }\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "\n",
    "            seizure_vote = self.df_train.iloc[idx]['seizure_vote']\n",
    "            lpd_vote = self.df_train.iloc[idx]['lpd_vote']\n",
    "            gpd_vote = self.df_train.iloc[idx]['gpd_vote']\n",
    "            lrda_vote = self.df_train.iloc[idx]['lrda_vote']\n",
    "            grda_vote = self.df_train.iloc[idx]['grda_vote']\n",
    "            other_vote = self.df_train.iloc[idx]['other_vote']\n",
    "            target = self.df_train.iloc[idx]['target']\n",
    "\n",
    "            sample = {\n",
    "                \"values\": sample[\"values\"],\n",
    "                \"seizure_vote\": seizure_vote,\n",
    "                \"lpd_vote\": lpd_vote,\n",
    "                \"gpd_vote\": gpd_vote,\n",
    "                \"lrda_vote\": lrda_vote,\n",
    "                \"grda_vote\": grda_vote,\n",
    "                \"other_vote\": other_vote,\n",
    "                \"target\": target\n",
    "            }\n",
    "        else:\n",
    "            #spectrogram_id eeg_id patient_id\n",
    "            parquet_path = os.path.join(self.data_path, str(self.df_train.iloc[idx]['spectrogram_id']) + \".parquet\")\n",
    "            parquet_table = pq.read_table(parquet_path)\n",
    "            \n",
    "            sample = {\"values\" : parquet_table.to_pandas().values[:, 1:], # drop the time column\n",
    "                \"min\" : 0,\n",
    "                \"max\" : 0\n",
    "                }\n",
    "            if self.transform:\n",
    "                sample = self.transform(sample)\n",
    "            \n",
    "            sample = {\n",
    "                \"values\": sample[\"values\"],\n",
    "                \"patient_id\": self.df_train.iloc[idx]['patient_id']\n",
    "            }\n",
    "\n",
    "        return sample\n",
    "\n",
    "\n",
    "def process_training_csv(csv_file):\n",
    "    \"\"\"\n",
    "    csv preprocessing from example notebook:\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(csv_file)\n",
    "    TARGETS = df.columns[-6:]\n",
    "    # Creating a Unique EEG Segment per eeg_id:\n",
    "    # The code groups (groupby) the EEG data (df) by eeg_id. Each eeg_id represents a different EEG recording.\n",
    "    # It then picks the first spectrogram_id and the earliest (min) spectrogram_label_offset_seconds for each eeg_id. This helps in identifying the starting point of each EEG segment.\n",
    "    # The resulting DataFrame train has columns spec_id (first spectrogram_id) and min (earliest spectrogram_label_offset_seconds).\n",
    "    train = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "        {'spectrogram_id':'first','spectrogram_label_offset_seconds':'min'})\n",
    "    train.columns = ['spec_id','min']\n",
    "    # Finding the Latest Point in Each EEG Segment:\n",
    "    # The code again groups the data by eeg_id and finds the latest (max) spectrogram_label_offset_seconds for each segment.\n",
    "    # This max value is added to the train DataFrame, representing the end point of each EEG segment.\n",
    "    tmp = df.groupby('eeg_id')[['spectrogram_id','spectrogram_label_offset_seconds']].agg(\n",
    "        {'spectrogram_label_offset_seconds':'max'})\n",
    "    train['max'] = tmp\n",
    "    # The code adds the patient_id for each eeg_id to the train DataFrame. This links each EEG segment to a specific patient.\n",
    "    tmp = df.groupby('eeg_id')[['patient_id']].agg('first')\n",
    "    train['patient_id'] = tmp\n",
    "    # The code sums up the target variable counts (like votes for seizure, LPD, etc.) for each eeg_id.\n",
    "    tmp = df.groupby('eeg_id')[TARGETS].agg('sum') \n",
    "    for t in TARGETS:\n",
    "        train[t] = tmp[t].values\n",
    "    # It then normalizes these counts so that they sum up to 1. This step converts the counts into probabilities, which is a common practice in classification tasks.\n",
    "    y_data = train[TARGETS].values \n",
    "    y_data = y_data / y_data.sum(axis=1,keepdims=True)\n",
    "    train[TARGETS] = y_data\n",
    "    # For each eeg_id, the code includes the expert_consensus on the EEG segment's classification.\n",
    "    tmp = df.groupby('eeg_id')[['expert_consensus']].agg('first')\n",
    "    train['target'] = tmp\n",
    "    # This makes eeg_id a regular column, making the DataFrame easier to work with.\n",
    "    train = train.reset_index() \n",
    "    print('Train non-overlapp eeg_id shape:', train.shape)\n",
    "    return train\n",
    "\n",
    "\n",
    "class MiddleCrop(object):\n",
    "    \"\"\"Crop the spectrogram in a sample, centred in the middle.\n",
    "\n",
    "    Args:\n",
    "        output_size: Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, output_size=300):\n",
    "        self.output_size = output_size\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        # //2 for average, //2 for 2 seconds per bin (min and max are in seconds, spectrogram is 2 seconds per value)\n",
    "        start_from = int((sample[\"min\"] + sample[\"max\"]) // 4) \n",
    "        cropped = sample[\"values\"][start_from:start_from+self.output_size, :]\n",
    "        return {\"values\": cropped, \"min\": 0, \"max\": self.output_size*2}\n",
    "    \n",
    "class Impute(object):\n",
    "    \"\"\"\n",
    "    replace NaNs with mean\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self.nan_imputer = SimpleImputer(strategy='mean')\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        imputed = self.nan_imputer.fit_transform(sample[\"values\"])\n",
    "        return {\"values\": imputed, \"min\": sample[\"min\"], \"max\": sample[\"max\"]}\n",
    "    \n",
    "class StackFrequencyBands(object):\n",
    "    \"\"\"Stack the 4 frequency bands of the spectrogram in a sample.\n",
    "\n",
    "    \"Args:\n",
    "        sample: 300x400 spectrogram\n",
    "        returns: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        values = sample[\"values\"]\n",
    "        split_arrays = np.array(np.split(values, 4, axis=1))\n",
    "        return {\n",
    "            \"values\": split_arrays,\n",
    "                \"min\": sample[\"min\"],\n",
    "                \"max\": sample[\"max\"]\n",
    "        }\n",
    "\n",
    "class LogTransform(object):\n",
    "    \"\"\"Apply log transformation to the spectrogram in a sample.\n",
    "\n",
    "    Args:\n",
    "        sample: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "        returns: 4x300x100 spectrogram (band/channel, time, frequency)\n",
    "    \"\"\"\n",
    "    def __call__(self, sample):\n",
    "        values = sample[\"values\"]\n",
    "        log_transformed = np.log(values + 1)\n",
    "        return {\n",
    "            \"values\": log_transformed,\n",
    "                \"min\": sample[\"min\"],\n",
    "                \"max\": sample[\"max\"]\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0ccfa982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:02:06.526127Z",
     "iopub.status.busy": "2024-03-13T17:02:06.524921Z",
     "iopub.status.idle": "2024-03-13T17:02:06.720563Z",
     "shell.execute_reply": "2024-03-13T17:02:06.719301Z"
    },
    "papermill": {
     "duration": 0.204235,
     "end_time": "2024-03-13T17:02:06.723881",
     "exception": false,
     "start_time": "2024-03-13T17:02:06.519646",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch.nn.init as init\n",
    "import torch.nn.init as init\n",
    "import gc\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\"\"\"\n",
    "Ideas To Prevent Loss Nans\n",
    "1. Normalize Data Better\n",
    "2. Less Deep / Wide Architecture\n",
    "3. CNN instead of FCNN\n",
    "\"\"\"\n",
    "class AEW(torch.nn.Module):\n",
    "    def __init__(self, numFrequencies, numRows, numFeatures=1000):\n",
    "        super().__init__()\n",
    "\n",
    "        # Building a linear encoder with Batch Normalization\n",
    "        self.encoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFrequencies * numRows, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFeatures),\n",
    "            torch.nn.ReLU(),\n",
    "        )\n",
    "\n",
    "        # Building a linear decoder with Batch Normalization\n",
    "        self.decoder = torch.nn.Sequential(\n",
    "            torch.nn.Linear(numFeatures, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, 2048),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(2048, numFrequencies * numRows),\n",
    "            torch.nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "        # Apply Xavier initialization to the weights\n",
    "        for m in self.modules():\n",
    "            if isinstance(m, nn.Linear):\n",
    "                init.xavier_uniform_(m.weight)\n",
    "\n",
    "    def forward(self, x):\n",
    "        encoded = self.encoder(x)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6286ce3",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:02:06.734839Z",
     "iopub.status.busy": "2024-03-13T17:02:06.734444Z",
     "iopub.status.idle": "2024-03-13T17:02:17.227268Z",
     "shell.execute_reply": "2024-03-13T17:02:17.225920Z"
    },
    "papermill": {
     "duration": 10.502069,
     "end_time": "2024-03-13T17:02:17.230514",
     "exception": false,
     "start_time": "2024-03-13T17:02:06.728445",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1 µs, total: 5 µs\n",
      "Wall time: 8.11 µs\n",
      "Num Frequencies: 400\n",
      "Using:  cpu\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "# ENGINEER FEATURES\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "PATH = '/kaggle/input/hms-harmful-brain-activity-classification/train_spectrograms/'\n",
    "\n",
    "SPEC_FREQS = len(pd.read_parquet(f'{PATH}1000086677.parquet').columns[1:])\n",
    "print(f\"Num Frequencies: {SPEC_FREQS}\")\n",
    "numFeatures = 400\n",
    "# if torch.cuda.device_count() > 1:\n",
    "#     device = torch.cuda.current_device()\n",
    "#     print('Use Multi GPU', device)\n",
    "# elif torch.cuda.device_count() == 1 and use_gpu:\n",
    "#     device = torch.cuda.current_device()\n",
    "#     print('Use GPU', device)\n",
    "# else:\n",
    "#     print(\"use CPU\")\n",
    "#     device = torch.device('cpu')  # sets the device to be CPU\n",
    "#     print(device)\n",
    "device = torch.device('cpu') # delete when issue resolved\n",
    "\n",
    "print(\"Using: \", device)\n",
    "\"\"\"\n",
    "Define 10min feature autoencoder\n",
    "\"\"\"\n",
    "model_10min = AEW(SPEC_FREQS, 300, numFeatures=numFeatures)\n",
    "model_10min = model_10min.to(device)\n",
    "loss_function_10min = torch.nn.MSELoss()\n",
    "optimizer_10min = torch.optim.Adam(model_10min.parameters(),\n",
    "                            lr = 3e-4,\n",
    "                            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c976793",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T17:02:17.241233Z",
     "iopub.status.busy": "2024-03-13T17:02:17.240806Z",
     "iopub.status.idle": "2024-03-13T22:44:41.955672Z",
     "shell.execute_reply": "2024-03-13T22:44:41.952422Z"
    },
    "papermill": {
     "duration": 20544.728478,
     "end_time": "2024-03-13T22:44:41.963527",
     "exception": false,
     "start_time": "2024-03-13T17:02:17.235049",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train non-overlapp eeg_id shape: (17089, 12)\n",
      "Training Autoencoder on 17089 datapoints with batch size 100\n",
      "Batches 171: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/8 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 0 Summary: Avg Loss 10min: 0.03024245012682258\n",
      "Saving new best model epoch 0 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [44:29<5:11:23, 2669.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 1 Summary: Avg Loss 10min: 0.01273107567627789\n",
      "Saving new best model epoch 1 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [1:20:05<3:55:33, 2355.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 2 Summary: Avg Loss 10min: 0.007710987821831341\n",
      "Saving new best model epoch 2 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [1:55:50<3:08:17, 2259.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 3 Summary: Avg Loss 10min: 0.0068581397509017185\n",
      "Saving new best model epoch 3 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [2:36:43<2:35:43, 2335.85s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 4 Summary: Avg Loss 10min: 0.006378850439421789\n",
      "Saving new best model epoch 4 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [3:22:59<2:04:43, 2494.56s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 5 Summary: Avg Loss 10min: 0.006225711611584264\n",
      "Saving new best model epoch 5 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [4:09:34<1:26:33, 2596.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 6 Summary: Avg Loss 10min: 0.005963674376103264\n",
      "Saving new best model epoch 6 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [4:55:08<44:01, 2641.69s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done batch 0... Done batch 5... Done batch 10... Done batch 15... Done batch 20... Done batch 25... Done batch 30... Done batch 35... Done batch 40... Done batch 45... Done batch 50... Done batch 55... Done batch 60... Done batch 65... Done batch 70... Done batch 75... Done batch 80... Done batch 85... Done batch 90... Done batch 95... Done batch 100... Done batch 105... Done batch 110... Done batch 115... Done batch 120... Done batch 125... Done batch 130... Done batch 135... Done batch 140... Done batch 145... Done batch 150... Done batch 155... Done batch 160... Done batch 165... Done batch 170... Epoch 7 Summary: Avg Loss 10min: 0.0057427994852439004\n",
      "Saving new best model epoch 7 at /kaggle/working/model_ten_min_best.pth\n",
      "Saving model at /kaggle/working/model_ten_min_latest.pth\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [5:42:23<00:00, 2567.92s/it]\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "torch.autograd.set_detect_anomaly(True)\n",
    "\n",
    "batch_size = 100\n",
    "\n",
    "spectrogram_dataset = SpectrogramDataset(\"train\", transform=transforms.Compose([\n",
    "    MiddleCrop(), Impute(), LogTransform()])\n",
    "    )\n",
    "\n",
    "dataloader = DataLoader(spectrogram_dataset, batch_size=batch_size,\n",
    "                        shuffle=True, num_workers=2)\n",
    "\n",
    "num_batches = len(spectrogram_dataset) // batch_size + 1\n",
    "\n",
    "print(f\"Training Autoencoder on {len(spectrogram_dataset)} datapoints with batch size {batch_size}\")\n",
    "print(f\"Batches {num_batches}:\", end=' ')\n",
    "num_epochs = 8 # fine with 2-3 epochs but should do more with GPU if possible\n",
    "\n",
    "best_loss = float('inf')\n",
    "best_epoch = -1\n",
    "TEN_MIN_PATH = \"/kaggle/working/model_ten_min_latest.pth\"\n",
    "BEST_TEN_MIN_PATH = \"/kaggle/working/model_ten_min_best.pth\"\n",
    "\n",
    "for epoch in tqdm(range(num_epochs)): \n",
    "    \n",
    "    epoch_loss_10min = 0.0\n",
    "    \n",
    "    for i, sample_batched in enumerate(dataloader):       \n",
    "#         if (i==3):\n",
    "#             break\n",
    "        input_10min_list = []\n",
    "    \n",
    "        this_batch_size = sample_batched[\"values\"].shape[0]\n",
    "        for k in range(this_batch_size):\n",
    "            \n",
    "            raw_values_10min = sample_batched[\"values\"][k]\n",
    "            \n",
    "            raw_values_10min = raw_values_10min.flatten()\n",
    "            normalized_values_10min = (raw_values_10min - raw_values_10min.min()) / (raw_values_10min.max() - raw_values_10min.min())\n",
    "            input_10min_list.append(normalized_values_10min)\n",
    "     \n",
    "        # Forward pass through the autoencoders\n",
    "        input_10min_batch = torch.stack(input_10min_list).float().to(device)   \n",
    "        output_10min_batch = model_10min(input_10min_batch)\n",
    "\n",
    "        # Calculate loss and perform optimization for ten_min autoencoder\n",
    "        loss_10min = loss_function_10min(output_10min_batch, input_10min_batch)\n",
    "        optimizer_10min.zero_grad()\n",
    "        loss_10min.backward()\n",
    "        optimizer_10min.step()\n",
    "\n",
    "        # Accumulate epoch loss\n",
    "        epoch_loss_10min += loss_10min.item()\n",
    "        \n",
    "        # Clean up to avoid memory issues\n",
    "        del output_10min_batch, input_10min_batch, input_10min_list\n",
    "        \n",
    "        if i % 5 == 0:\n",
    "            print(f\"Done batch {i}\", end = '... ')\n",
    "\n",
    "    # Calculate average loss for the epoch\n",
    "    avg_loss_ten_min = epoch_loss_10min / num_batches\n",
    "\n",
    "    print(f\"Epoch {epoch} Summary: Avg Loss 10min: {avg_loss_ten_min}\")\n",
    "    \n",
    "    if avg_loss_ten_min < best_loss:\n",
    "        best_loss = avg_loss_ten_min\n",
    "        best_epoch = epoch\n",
    "        print(f\"Saving new best model epoch {epoch} at {BEST_TEN_MIN_PATH}\")\n",
    "        torch.save(model_10min.state_dict(), BEST_TEN_MIN_PATH)\n",
    "\n",
    "    # Save the trained model parameters\n",
    "\n",
    "    print(f\"Saving model at {TEN_MIN_PATH}\")\n",
    "    torch.save(model_10min.state_dict(), TEN_MIN_PATH)\n",
    "\n",
    "del model_10min, loss_10min, optimizer_10min\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12877cdf",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-03-13T22:44:42.040081Z",
     "iopub.status.busy": "2024-03-13T22:44:42.039378Z",
     "iopub.status.idle": "2024-03-13T22:44:42.047584Z",
     "shell.execute_reply": "2024-03-13T22:44:42.046519Z"
    },
    "papermill": {
     "duration": 0.052903,
     "end_time": "2024-03-13T22:44:42.051296",
     "exception": false,
     "start_time": "2024-03-13T22:44:41.998393",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best epoch: 7\n",
      "Best loss: 0.0057427994852439004\n"
     ]
    }
   ],
   "source": [
    "print(f\"Best epoch: {best_epoch}\")\n",
    "print(f\"Best loss: {best_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e679f198",
   "metadata": {
    "papermill": {
     "duration": 0.032149,
     "end_time": "2024-03-13T22:44:42.116630",
     "exception": false,
     "start_time": "2024-03-13T22:44:42.084481",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 7469972,
     "sourceId": 59093,
     "sourceType": "competition"
    }
   ],
   "dockerImageVersionId": 30646,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 20571.839041,
   "end_time": "2024-03-13T22:44:45.480321",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-03-13T17:01:53.641280",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
